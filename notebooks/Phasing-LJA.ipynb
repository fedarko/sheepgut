{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform read smoothing then assemble with LJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:57.580024Z",
     "iopub.status.busy": "2021-10-16T02:49:57.578415Z",
     "iopub.status.idle": "2021-10-16T02:49:57.937571Z",
     "shell.execute_reply": "2021-10-16T02:49:57.936229Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:57.942682Z",
     "iopub.status.busy": "2021-10-16T02:49:57.941820Z",
     "iopub.status.idle": "2021-10-16T02:49:59.163970Z",
     "shell.execute_reply": "2021-10-16T02:49:59.164651Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import pysam\n",
    "import skbio\n",
    "from collections import defaultdict\n",
    "from linked_mutations_utils import find_mutated_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Smooth reads\n",
    "\n",
    "Lots of this code is duplicated from the `Phasing-01-MakeGraph.ipynb` notebook in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:59.179723Z",
     "iopub.status.busy": "2021-10-16T02:49:59.178829Z",
     "iopub.status.idle": "2021-10-16T02:49:59.181967Z",
     "shell.execute_reply": "2021-10-16T02:49:59.181245Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying mutated positions in genome CAMP...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Poppy/mfedarko/sheepgut/notebooks/pileup.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(picklepath)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicklepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpicklefile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicklefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-be2831081813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Identifying mutated positions in genome {seq2name[seq]}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmutated_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_mutated_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(mutated_positions):,} mutated positions in {seq2name[seq]}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Poppy/mfedarko/sheepgut/notebooks/linked_mutations_utils.py\u001b[0m in \u001b[0;36mfind_mutated_positions\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0monly\u001b[0m \u001b[0minclude\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mcoverage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mat\u001b[0m \u001b[0mleast\u001b[0m \u001b[0mMINCOV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mseq2pos2pileup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpileup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmutated_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2pos2pileup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Poppy/mfedarko/sheepgut/notebooks/pileup.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(picklepath)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# https://stackoverflow.com/a/18261955\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicklepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpicklefile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicklefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bf = pysam.AlignmentFile(\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "output_dir = \"phasing-data/smoothed-reads/\"\n",
    "\n",
    "no_indoor_voice = True\n",
    "\n",
    "seq2num_supp_alns_ignored = defaultdict(int)\n",
    "\n",
    "def write_out_reads(filepath, readname2seq):\n",
    "    # Notably, this uses the \"a\" (append) method in order to add to the end of a file\n",
    "    with open(filepath, \"a\") as of:\n",
    "        for readname in readname2seq:\n",
    "            # Write out both the header and the sequence for each read\n",
    "            of.write(f\">{readname}\\n{str(smoothed_reads[readname])}\\n\")\n",
    "            \n",
    "ALN_UPDATE_FREQ = 1000\n",
    "ALN_BUFFER_FREQ = 1000\n",
    "            \n",
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    fasta = skbio.DNA.read(f\"../seqs/{seq}.fasta\")\n",
    "    \n",
    "    output_smoothed_reads_file = os.path.join(output_dir, f\"{seq}_smoothed_reads.fasta\")\n",
    "    \n",
    "    # Identify all (0-indexed, so compatible with skbio / pysam!)\n",
    "    # mutated positions in this genome up front to save time.\n",
    "    #\n",
    "    # Equivalently, we could also just take in an arbitrary VCF as input\n",
    "    # (e.g. one produced from another variant calling tool), although we'd\n",
    "    # need to be careful to only include SNVs and not indels/etc...\n",
    "    \n",
    "    print(f\"Identifying mutated positions in genome {seq2name[seq]}...\")\n",
    "    mutated_positions = find_mutated_positions(seq)\n",
    "    print(f\"Found {len(mutated_positions):,} mutated positions in {seq2name[seq]}.\")\n",
    "    \n",
    "    print(\"Going through these positions...\")\n",
    "    \n",
    "    # This should already be implicitly sorted, I think, but the code below relies on mutated_positions being\n",
    "    # in the exact same order as expected. So we may as well be paranoid.\n",
    "    mutated_positions = sorted(mutated_positions)\n",
    "    \n",
    "    # Instead of just writing out every smoothed alignment as soon as we generate it, we build up a \"buffer\"\n",
    "    # of these alignments and then write a bunch out at once. This way we limit slowdown due to constantly\n",
    "    # having to open/close files. I don't really have a good source for this as best practice, but I remembered\n",
    "    # to do it while writing this code, so somewhere in College Park the CS faculty at Maryland are smiling\n",
    "    #\n",
    "    # Also fyi this maps read name to smoothed alignment (well, at this point, just read) sequence. The read name\n",
    "    # is useful to preserve in fasta files so we have some idea of provenance (where smoothed reads came from)\n",
    "    smoothed_aln_buffer = {}\n",
    "    \n",
    "    # Go through all linear alignments of each read to this genome, focusing (for now) on just the primary\n",
    "    # alignments...\n",
    "    ts1 = time.time()\n",
    "    for ai, aln in enumerate(bf.fetch(seq), 1):\n",
    "        \n",
    "        if ai % ALN_UPDATE_FREQ == 0:\n",
    "            print(\n",
    "                f\"\\tOn aln {ai:,} in seq {seq2name[seq]}. \"\n",
    "                f\"Time spent on {seq2name[seq]} so far: {time.time() - ts1:,.2f} sec.\"\n",
    "            )\n",
    "            \n",
    "        if aln.is_supplementary:\n",
    "            seq2num_supp_alns_ignored[seq] += 1\n",
    "            continue\n",
    "            \n",
    "        if aln.is_secondary:\n",
    "            raise ValueError(\n",
    "                \"Not to get political or anything, but you should've already filtered secondary alns out\"\n",
    "            )\n",
    "            \n",
    "        readname = aln.query_name\n",
    "        \n",
    "        if readname in smoothed_aln_buffer:\n",
    "            raise ValueError(\"Read has already been smoothed? Du sollst jetzt mit Gott sprechen.\")\n",
    "            \n",
    "        # Figure out where on the MAG this alignment \"hits.\" These are 0-indexed positions from Pysam.\n",
    "        # (reference_end points to the position after the actual final position, since these are designed to\n",
    "        # be interoperable with Python's half-open intervals.)\n",
    "        #\n",
    "        # Of course, there likely will be indels within this range: we're purposefully ignoring those here.\n",
    "        ref_start = aln.reference_start\n",
    "        ref_end = aln.reference_end - 1\n",
    "        \n",
    "        # This should never happen (TM)\n",
    "        if ref_start >= ref_end:\n",
    "            raise ValueError(\n",
    "                f\"Ref start {ref_start:,} >= ref end {ref_end:,} for primary aln of read {readname}?\"\n",
    "            )\n",
    "        \n",
    "        # Smoothed sequence; we'll edit this so that if this read has (mis)matches to any called mutated\n",
    "        # positions, these positions are updated with the read's aligned nucleotides at these positions.\n",
    "        smoothed_aln_seq = fasta[ref_start: ref_end + 1]\n",
    "        \n",
    "        # just for debugging: track the exact edits made to smoothed_aln_seq\n",
    "        replacements_made = {}\n",
    "        \n",
    "        ap = aln.get_aligned_pairs(matches_only=True)\n",
    "        \n",
    "        # Iterating through the aligned pairs is expensive. Since read lengths are generally in the thousands\n",
    "        # to tens of thousands of bp (which is much less than the > 1 million bp length of any bacterial genome),\n",
    "        # we set things up so that we only iterate through the aligned pairs once. We maintain an integer, mpi,\n",
    "        # that is a poor man's \"pointer\" to an index in mutated_positions.\n",
    "        \n",
    "        mpi = 0\n",
    "        \n",
    "        # Go through this aln's aligned pairs. As we see each pair, compare the pair's reference position\n",
    "        # (refpos) to the mpi-th mutated position (herein referred to as \"mutpos\").\n",
    "        #\n",
    "        # If refpos >  mutpos, increment mpi until refpos <= mutpos (stopping as early as possible).\n",
    "        # If refpos == mutpos, we have a match! Update readname2mutpos2ismutated[mutpos] based on\n",
    "        #                      comparing the read to the reference at the aligned positions.\n",
    "        # If refpos <  mutpos, continue to the next pair.\n",
    "        \n",
    "        for pair in ap:\n",
    "            \n",
    "            refpos = pair[1]\n",
    "            mutpos = mutated_positions[mpi]\n",
    "            \n",
    "            no_mutations_to_right_of_here = False\n",
    "            \n",
    "            # Increment mpi until we get to the next mutated position at or after the reference pos for this\n",
    "            # aligned pair (or until we run out of mutated positions).\n",
    "            while refpos > mutpos:\n",
    "                mpi += 1\n",
    "                if mpi < len(mutated_positions):\n",
    "                    mutpos = mutated_positions[mpi]\n",
    "                else:\n",
    "                    no_mutations_to_right_of_here = True\n",
    "                    break\n",
    "            \n",
    "            # I expect this should happen only for reads aligned near the right end of the genome.\n",
    "            if no_mutations_to_right_of_here:\n",
    "                break\n",
    "            \n",
    "            # If the next mutation occurs after this aligned pair, continue on to a later pair.\n",
    "            if refpos < mutpos:\n",
    "                continue\n",
    "                \n",
    "            # If we've made it here, refpos == mutpos!\n",
    "            # (...unless I messed something up in how I designed this code.)\n",
    "            if refpos != mutpos:\n",
    "                raise ValueError(\"This should never happen!\")\n",
    "                \n",
    "            # Finally, get the nucleotide aligned to this mutated position from this read.\n",
    "            readpos = pair[0]\n",
    "            read_nt = aln.query_sequence[readpos]\n",
    "            \n",
    "            # We don't need to do anything if this read already matches the reference MAG at this position\n",
    "            if read_nt == str(fasta[mutpos]):\n",
    "                if no_indoor_voice:\n",
    "                    print(f\"Primary aln of read {readname} matches ref at mut pos {mutpos + 1:,}: both {read_nt}\")\n",
    "            else:\n",
    "                # Record this specific \"allele\" for this read.\n",
    "                relative_pos_on_aln = mutpos - ref_start\n",
    "                smoothed_aln_seq = smoothed_aln_seq.replace([relative_pos_on_aln], read_nt)\n",
    "                replacements_made[relative_pos_on_aln] = read_nt\n",
    "                \n",
    "        if no_indoor_voice:\n",
    "            print(f\"Primary aln of read {readname} required {len(replacements_made):,} replacements!\")\n",
    "        \n",
    "        # Now that we've finished processing all called mutations that this alignment spans, prepare it\n",
    "        # to be written out to a FASTA file. See comments above on smoothed_aln_buffer, and why we don't\n",
    "        # just write everything out as soon as it's ready.\n",
    "        #\n",
    "        # (Also, we've already guaranteed readname isn't already in smoothed_aln_buffer, so no need to worry\n",
    "        # about accidentally overwriting something from earlier.)\n",
    "        smoothed_aln_buffer[readname] = smoothed_aln_seq\n",
    "        \n",
    "        # Notably, we don't necessarily write out *exactly* ALN_BUFFER_FREQ reads at once -- skipping alignments\n",
    "        # due to them being supplementary, etc. (actually no need for an \"etc.\", that's literally the only\n",
    "        # possible reason as of writing, but whatever) doesn't stop ai from going up. Shouldn't make a difference\n",
    "        # unless we have a zillion supplementary alignments.\n",
    "        if ai % ALN_BUFFER_FREQ == 0:\n",
    "            write_out_reads(output_smoothed_reads_file, smoothed_aln_buffer)\n",
    "            # Clear the buffer\n",
    "            smoothed_aln_buffer = {}\n",
    "        \n",
    "    # We're probably going to have left over smoothed reads that we still haven't written out, unless things\n",
    "    # worked out so that on the final alignment we saw ai was exactly divisible by ALN_BUFFER_FREQ (and that's\n",
    "    # pretty unlikely unless you set the buffer freq to a low number). So make one last dump of the buffer.\n",
    "    if len(smoothed_aln_buffer) > 0:\n",
    "        write_out_reads(output_smoothed_reads_file, smoothed_aln_buffer)\n",
    "    \n",
    "    print(f\"Done with {seq}! Took {time.time() - ts1:,.2f} sec.\")\n",
    "    print(f\"\\t(FYI, we ignored {seq2num_supp_alns_ignored[seq]:,} supplementary alignments.)\")\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1:,} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run LJA on these smoothed reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/mfedarko/software/LJA/bin/lja \\\n",
    "    --reads phasing-data/smoothed-reads/edge_6104_smoothed_reads.fasta \\\n",
    "    --output-dir phasing-data/smoothed-reads/edge_6104_lja\n",
    "\n",
    "!/home/mfedarko/software/LJA/bin/lja \\\n",
    "    --reads phasing-data/smoothed-reads/edge_1671_smoothed_reads.fasta \\\n",
    "    --output-dir phasing-data/smoothed-reads/edge_1671_lja\n",
    "\n",
    "!/home/mfedarko/software/LJA/bin/lja \\\n",
    "    --reads phasing-data/smoothed-reads/edge_2358_smoothed_reads.fasta \\\n",
    "    --output-dir phasing-data/smoothed-reads/edge_2358_lja"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
