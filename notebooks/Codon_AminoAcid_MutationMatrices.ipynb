{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data for \"mutation matrices\"\n",
    "\n",
    "Both for codons (e.g. ATG, TGC) and amino acids (e.g. M, C).\n",
    "\n",
    "**NOTE 1:** Because this boils down to calling [`AlignedSegment.get_aligned_pairs()`](https://pysam.readthedocs.io/en/latest/api.html#pysam.AlignedSegment.get_aligned_pairs) once for every read aligned to the selected genomes, **this notebook is currently pretty slow**! I've optimized things to the point where (assuming\n",
    "there are roughly 1,470,000 reads aligned to each genome, and that the runtime for other genomes is similar to that of the CAMP genome) this notebook should take around 8-12 hours to run on our cluster.\n",
    "\n",
    "If necessary / desired it should be possible to speed this up even more, using stuff like parallelization / writing this in a faster language like C / etc. There may also be methods in pysam I've overlooked that will help do this faster.\n",
    "\n",
    "**NOTE 2:** This doesn't actually generate the figures for the matrices -- it just outputs JSON files to a folder named `matrix-jsons/`, and another notebook will generate those. This is intended to make it easier to regenerate the figures using different styles / etc. without having to wait hours for this stuff to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import json\n",
    "import pysam\n",
    "import skbio\n",
    "from collections import defaultdict, Counter\n",
    "from statistics import mean\n",
    "from parse_sco import parse_sco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data structures that we'll store frequency data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64x63 dict: each key is a triplet of {A, C, G, T}, and each value is another dict with all the other codons\n",
    "codon2codon2freq = {}\n",
    "\n",
    "# 21x20 dict: each key is a proteinogenic amino acid (A, C, D, E, F, ...), limited to just\n",
    "# stuff in the standard genetic code (i.e. ignoring selenocystine and pyrrolsine) but including\n",
    "# \"*\", representing a stop codon.\n",
    "aa2aa2freq = {}\n",
    "\n",
    "# 64-key dict: maps each triplet to an integer indicating how frequently this triplet occurs in all genes\n",
    "# in the genomes (i.e. not counting mutations into this triplet).\n",
    "codon2freq = {}\n",
    "\n",
    "# 21-key dict: maps amino acid/stop codon to integer indicating frequency across all genes.\n",
    "aa2freq = {}\n",
    "\n",
    "# There's probably a fancier way of generating this list, but this is fine.\n",
    "codons = []\n",
    "# Also, we figure out the reverse complements of each of the 64 3-mers in advance -- this avoids\n",
    "# us having to call str(skbio.DNA(c).reverse_complement()) every time we see a codon, and saves a tiny\n",
    "# amount of time per read (the skbio approach took ~9e-5 seconds every time; the new approach takes ~9e-7\n",
    "# seconds every time). Considering we're going through well over a million reads, the time savings comes out\n",
    "# to ... 130.977 seconds, aka 2 minutes 10 seconds, if I'm computing this correctly. So, not much, but it's\n",
    "# something!\n",
    "codon2revcomp = {}\n",
    "nts = \"ACGT\"\n",
    "for i in nts:\n",
    "    for j in nts:\n",
    "        for k in nts:\n",
    "            c = \"{}{}{}\".format(i, j, k)\n",
    "            codons.append(c)\n",
    "            codon2revcomp[c] = str(skbio.DNA(c).reverse_complement())\n",
    "\n",
    "aas = set([])\n",
    "for c in codons:\n",
    "    aas.add(str(skbio.DNA(c).translate()))\n",
    "    \n",
    "# Initialize dicts to 0s\n",
    "for c1 in codons:\n",
    "    codon2codon2freq[c1] = {c2: 0 for c2 in set(codons) - set([c1])}\n",
    "    codon2freq[c1] = 0\n",
    "    \n",
    "for aa1 in aas:\n",
    "    aa2aa2freq[aa1] = {aa2: 0 for aa2 in set(aas) - set([aa1])}\n",
    "    aa2freq[aa1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go through all reads aligned to each genome and figure out which genes they intersect and which codons in these genes they fully cover\n",
    "\n",
    "Define a dict which we'll use to keep track of aligned codon frequencies for each codon, for each gene, for each genome.\n",
    "\n",
    "- For each read, see which predicted genes (if any) this read intersects within the genome. Note that \"intersects\" doesn't mean \"fully covers\".\n",
    "\n",
    "- For each of these genes, see which codons (if any) this read fully covers within the gene.\n",
    "\n",
    "- Increment aligned codon frequencies for all codons accordingly.\n",
    "\n",
    "The reason we do things this way, as opposed to iterating over just the reads overlapping each codon in each gene, is that doing things that way is really slow! I'm pretty sure it's because \"find out which reads overlap this region\" is a pretty slow operation when working with large datasets -- and also since these are long reads, doing this on the level of each codon means we're effectively doing a lot of redundant work (you can imagine that, for a given codon, the odds are pretty good that most reads overlapping it will also overlap adjacent codon(s))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps sequence IDs to genes (keyed by their Index in the .sco file) to codons (keyed by (0-indexed!)\n",
    "# left end, i.e. the lower of the two positional boundaries of the codon, regardless of if its gene\n",
    "# is on the + or - strand) to observed aligned codon frequencies (keyed by just the triplet, e.g. \"AAA\").\n",
    "#\n",
    "# Example:\n",
    "# {\"edge_6104\":                                Sequence\n",
    "#     {1:                                      Gene index in the .sco file\n",
    "#         {265:                                Left codon position\n",
    "#             {\"TTA\": 1000, \"TTT\": 1, ... }    Aligned codon frequencies for this particular codon\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "seq2gene2codon2alignedcodons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pysam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f11e58767a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSEQS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfasta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskbio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../seqs/{}.fasta\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_sco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../seqs/genes/{}.sco\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pysam' is not defined"
     ]
    }
   ],
   "source": [
    "bf = pysam.AlignmentFile(\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "\n",
    "tT1 = time.time()\n",
    "for seq in SEQS:\n",
    "    df = parse_sco(\"../seqs/genes/{}.sco\".format(seq))\n",
    "    \n",
    "    # We don't actually store any results in this, but we do use it for a slight optimization\n",
    "    gene2isrev = {}\n",
    "    \n",
    "    # Initialize some of the data structures\n",
    "    # NOTE: this is kind of slow. However, it still finishes within a few seconds, so not the most\n",
    "    # important thing to optimize\n",
    "    seq2gene2codon2alignedcodons[seq] = {}\n",
    "    for gene_data in df.itertuples():\n",
    "        \n",
    "        # Should never happen, but check this so that we can compute overlap easily and with peace of mind later\n",
    "        if gene_data.LeftEnd >= gene_data.RightEnd:\n",
    "            raise ValueError(\"Gene {}'s coordinates seem messed up: left = {}, right = {}\".format(\n",
    "                gene_data.Index, gene_data.LeftEnd, gene_data.RightEnd\n",
    "            ))\n",
    "        \n",
    "        seq2gene2codon2alignedcodons[seq][gene_data.Index] = {}\n",
    "        gene2isrev[gene_data.Index] = (gene_data.Strand == \"-\")\n",
    "        \n",
    "        codon_positions = [\n",
    "            i for i in range(gene_data.LeftEnd, gene_data.RightEnd + 1, 3)\n",
    "        ]\n",
    "\n",
    "        # For each codon in this gene...\n",
    "        for cpleft in codon_positions:\n",
    "            seq2gene2codon2alignedcodons[seq][gene_data.Index][cpleft] = defaultdict(int)\n",
    "            \n",
    "    print(\"Finished initialization for seq = {}\".format(seq))\n",
    "    readtimes = []\n",
    "    \n",
    "    # Note that this isn't really a \"read\" so much as it is an aligned linear segment (and a read\n",
    "    # can have multiple such segments derived from it, as discussed above).\n",
    "    for ri, read in enumerate(bf.fetch(seq), 1):\n",
    "        \n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Find all genes that this read intersects in this genome\n",
    "        \n",
    "        # These are 0-indexed coordinates (and segright is offset to the right by one; see\n",
    "        # https://pysam.readthedocs.io/en/latest/api.html#pysam.AlignedSegment.reference_end)\n",
    "        segleft = read.reference_start\n",
    "        segright = read.reference_end\n",
    "        \n",
    "        if segleft is None or segright is None:\n",
    "            raise ValueError(\"Read {} is unmapped? This shouldn't happen!\".format(seg.query_name))\n",
    "        \n",
    "        if segleft >= segright:\n",
    "            raise ValueError(\"Read {}'s coordinates in pysam seem messed up: left = {}, right = {}\".format(\n",
    "                seg.query_name, segleft, segright\n",
    "            ))\n",
    "        \n",
    "        # Convert aligned segment boundaries to 1-indexed coordinates to make comparing with gene\n",
    "        # coordinates from the .sco file easier.\n",
    "        # Since segright was already offset to the right by 1, we don't need to do anything for it\n",
    "        # (the gene coordinates are exact: a gene from [266, 712] starts at base 266 and ends at base 712,\n",
    "        # using 1-indexing. So in order to make the read boundaries match, we'd add 1 for segright and then\n",
    "        # subract 1 since segright was already 1 base off -- and n + 1 - 1 = n. (...math is hard)\n",
    "        segleft += 1\n",
    "        \n",
    "        # Use vectorization to find genes overlapping this read: see https://stackoverflow.com/a/17071908\n",
    "        # for details on why parentheses, etc., and\n",
    "        # https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6\n",
    "        # for justification on why this is useful (tldr: makes code go fast)\n",
    "        genes_overlapping_read = list(\n",
    "            df.loc[(df[\"RightEnd\"] >= segleft) & (df[\"LeftEnd\"] <= segright)].itertuples()\n",
    "        )\n",
    "        # Note about the above thing that just happened: you may be shaking your fist and saying \"wait\n",
    "        # itertuples is slow!\" And yeah, kinda. But for whatever reason I've tried multiple times to keep\n",
    "        # genes_overlapping_read as a DataFrame (and then later vectorize stuff like checking that a given\n",
    "        # aligned pair covers a codon within the genes, etc) and the overhead costs seem to slow things down.\n",
    "        # I am sure it's possible to speed things up more, but right now things seem good enough.\n",
    "\n",
    "        # (Debugging code)\n",
    "        # print(\"{} genes overlap read {}\".format(len(genes_overlapping_read), ri))\n",
    "        # print(\"Read {}, which ranges from {} to {}, overlaps these genes:\".format(ri, segleft, segright))\n",
    "        # print(genes_overlapping_read)\n",
    "                \n",
    "        # If no genes overlap this read, we are free to move on to the next read.\n",
    "        if len(genes_overlapping_read) > 0:\n",
    "            \n",
    "            # Computing this is relatively slow, which is why we jump through so many hoops before we do this.\n",
    "            # Each entry in get_aligned_pairs() is a tuple with 2 elements:\n",
    "            # the first is the read pos and the second is the reference pos.\n",
    "            # TODO: would it be possible to only do this for certain positions we care about? get_aligned_pairs()\n",
    "            # returns a lot of stuff we don't need, e.g. regions of the read that don't intersect with any genes.\n",
    "            ap = read.get_aligned_pairs(matches_only=True)\n",
    "            \n",
    "            # Doesn't look like getting this in advance saves much time, but I don't think it hurts.\n",
    "            read_seq = read.query_sequence\n",
    "            \n",
    "            # We only consider the leftmost position of each codon, so we don't need to bother checking the last\n",
    "            # two pairs of positions (since neither could be the leftmost position of a codon that this read\n",
    "            # fully covers).\n",
    "            for api, pair1 in enumerate(ap[:-2]):\n",
    "\n",
    "                # Convert to 1-indexed position for ease of comparison with gene coordinates\n",
    "                pair1_refpos = pair1[1] + 1\n",
    "                  \n",
    "                havent_checked_next_pairs = True\n",
    "                for gene_data in genes_overlapping_read:\n",
    "                    gl = gene_data.LeftEnd\n",
    "                    \n",
    "                    # Check that this pair is located within this gene and is the leftmost position of a\n",
    "                    # codon in the gene. (Note that check works for both + or - strand genes.\n",
    "                    # Whether the leftmost position is the \"start\" [i.e. CP 1] or \"end\" [i.e. CP 3] of\n",
    "                    # the gene changes with the strand of the gene, but we'll account for that later on\n",
    "                    # when we reverse-complement the codon if needed.)                  \n",
    "                    if pair1_refpos >= gl and pair1_refpos <= gene_data.RightEnd - 2 and ((pair1_refpos - gl) % 3 == 0):\n",
    "                        \n",
    "                        # Nice! Looks like this read fully covers this codon.\n",
    "                        \n",
    "                        # If we haven't yet, check that this read doesn't skip over parts of the codon,\n",
    "                        # or stuff like that. The reason this check is located *here* (and not\n",
    "                        # before we loop over the genes) is that it seems like this is a faster strategy:\n",
    "                        # only run these checks once we KNOW that this pair looks like it fully covers a\n",
    "                        # codon, since many pairs might not meet that criteria.\n",
    "                        #\n",
    "                        # (And by recording that we've run this check once, in havent_checked_next_pairs,\n",
    "                        # we can save the time cost of running the check multiple times.)\n",
    "                        #\n",
    "                        # I feel like an insane person trying to optimize this so much lmao.\n",
    "                        if havent_checked_next_pairs:\n",
    "                            # Check that the pairs are all consecutive (i.e. no \"jumps\" in the read,\n",
    "                            # and no \"jumps\" in the reference)\n",
    "                            # Since we don't consider the last two pairs in ap, pair2 and pair3 should\n",
    "                            # always be available.\n",
    "                            pair2 = ap[api + 1]\n",
    "                            pair3 = ap[api + 2]\n",
    "\n",
    "                            # For an aligned pair, [0] is the read pos and [1] is the reference pos.\n",
    "                            # Result of caching this is probably negligible but... may as well\n",
    "                            p10 = pair1[0]\n",
    "                            p20 = pair2[0]\n",
    "                            readpos_consecutive = p20 == (p10 + 1) and pair3[0] == (p20 + 1)\n",
    "                            if not readpos_consecutive:\n",
    "                                break\n",
    "\n",
    "                            # (pair1_refpos is already off by 1 so no need to redo the addition operation)\n",
    "                            p21 = pair2[1]\n",
    "                            refpos_consecutive = p21 == pair1_refpos and pair3[1] == (p21 + 1)\n",
    "                            if not refpos_consecutive:\n",
    "                                break\n",
    "                            havent_checked_next_pairs = False\n",
    "                        \n",
    "                        # Figure out what the read actually *says* in the alignment here.\n",
    "                        # (It'll probably be a complete match most of the time, but there will\n",
    "                        # be some occasional mismatches -- and seeing those is ... the whole point\n",
    "                        # of this notebook.)\n",
    "\n",
    "                        # We make sure to index the read by read coords, not reference coords!\n",
    "                        aligned_codon = read_seq[p10: p10 + 3]\n",
    "\n",
    "                        # Finally, update information about codon frequencies.\n",
    "                        gi = gene_data.Index\n",
    "                        if gene2isrev[gi]:\n",
    "                            seq2gene2codon2alignedcodons[seq][gi][pair1_refpos][codon2revcomp[aligned_codon]] += 1\n",
    "                        else:\n",
    "                            seq2gene2codon2alignedcodons[seq][gi][pair1_refpos][aligned_codon] += 1\n",
    "\n",
    "        t2 = time.time()\n",
    "        readtimes.append(t2 - t1)\n",
    "        if ri % 100 == 0:\n",
    "            print(\"Seen {} reads so far in {}.\".format(ri, seq))\n",
    "            print(\"Total time taken thus far:          {} sec.\".format(t2 - tT1))\n",
    "            print(\"Average time per read for this seq: {} sec.\".format(mean(readtimes)))\n",
    "\n",
    "    # At this point, we've seen all the reads aligned to all the codons in this genome.\n",
    "    # We can now \"call\" mutations based on the frequencies we've counted.\n",
    "tT2 = time.time()\n",
    "\n",
    "print(\"Figuring all that out took a total of {} seconds.\".format(tT2 - tT1))\n",
    "\n",
    "bf.close()\n",
    "with open(\"matrix-jsons/seq2gene2codon2alignedcodons.json\", \"w\") as dumpster:\n",
    "    dumpster.write(json.dumps(seq2gene2codon2alignedcodons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the information we just computed for each genome, \"call\" mutations and store this information in the frequency data structures we set up earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-ed03929bc105>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ed03929bc105>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for seq in SEQS:\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for seq in SEQS:\n",
    "    fasta = skbio.DNA.read(\"../seqs/{}.fasta\".format(seq))\n",
    "    df = parse_sco(\"../seqs/genes/{}.sco\".format(seq))\n",
    "    for gene_data in df.itertuples():\n",
    "        for cpleft in range(gene_data.LeftEnd, gene_data.RightEnd + 1, 3):\n",
    "            \n",
    "            # Make note of the codon sequence and amino acid encoded by this codon in the \"reference\" genome.\n",
    "            # (Keep in mind that the gene data in the .sco file uses 1-indexed coords, so we need to convert\n",
    "            # accordingly.)\n",
    "            codon_dna = fasta[cpleft - 1: cpleft + 2]\n",
    "            if gene_data.Strand == \"-\":\n",
    "                codon_dna = codon_dna.reverse_complement()\n",
    "\n",
    "            codon_seq = str(codon_dna)\n",
    "            aa = str(codon_dna.translate())\n",
    "            \n",
    "            # Update frequencies accordingly.\n",
    "            codon2freq[codon_seq] += 1\n",
    "            aa2freq[aa] += 1\n",
    "            \n",
    "            # We can finally compute stats re: number of mismatching and matching codons.\n",
    "            aligned_codons = seq2gene2codon2alignedcodons[seq][gene_data.Index][cpleft]\n",
    "            num_aligned_codons = sum(aligned_codons.values())\n",
    "            alt_codon_frac = (num_aligned_codons - aligned_codons[codon_seq]) / num_aligned_codons\n",
    "            \n",
    "            # print(\"sum of vals of ac is {}\".format(sum(aligned_codons.values())))\n",
    "            # print(\"Codon {} from {} to {} in gene {} in seq {} has mutations: {}\".format(\n",
    "            #     codon_seq, cpleft, cpleft + 2, gene_data.Index, seq, aligned_codons\n",
    "            # ))\n",
    "            \n",
    "            # Using minfreq = 0.5%\n",
    "            if alt_codon_frac > 0.005:\n",
    "                \n",
    "                # Subset aligned_codons to just the alternate codons. I guess we could also just use \"del\".\n",
    "                alt_codons = {c: aligned_codons[c] for c in aligned_codons if c != codon_seq}\n",
    "                \n",
    "                # Retrieve max-freq alternate codon.\n",
    "                # Based on https://stackoverflow.com/a/280156.\n",
    "                # (Note that if there's a tie, the result is arbitrary. Shouldn't be a big deal. Making note\n",
    "                # of in the paper.)\n",
    "                max_freq_alt_codon = max(alt_codons, key=alt_codons.get)\n",
    "                codon2codon2freq[codon_seq][max_freq_alt_codon] += 1\n",
    "                \n",
    "                # print(\"Is mutation! And max freq alt codon is {}\".format(max_freq_alt_codon))\n",
    "                \n",
    "                # NOTE: I guess you could argue that we should do this another way, where we actually compute\n",
    "                # the translations of all the alt codons and then pick the most common AA/stop codon from there?\n",
    "                #\n",
    "                # You could argue this either way: doing it based on just the mutated codon keeps the matrices\n",
    "                # consistent and lessens the impact of small errors, while taking into account all alt codon\n",
    "                # translations could help show weird things where multiple mutations have similar consequences.\n",
    "                # Hmm.\n",
    "                #\n",
    "                # TODO: think about!\n",
    "                alt_codon_aa = str(skbio.DNA(max_freq_alt_codon).translate())\n",
    "                if alt_codon_aa != aa:\n",
    "                    aa2aa2freq[aa][alt_codon_aa] += 1\n",
    "                    # print(\"Is nonsyn mutation! Alt {} codes for {}; orig coded for {}\".format(\n",
    "                    #     max_freq_alt_codon, alt_codon_aa, aa\n",
    "                    # ))\n",
    "\n",
    "# Write out stuff for further analysis / in case of crisis\n",
    "with open(\"matrix-jsons/codon2codon2freq.json\", \"w\") as dumpster:\n",
    "    dumpster.write(json.dumps(codon2codon2freq))\n",
    "    \n",
    "with open(\"matrix-jsons/codon2freq.json\", \"w\") as dumpster:\n",
    "    dumpster.write(json.dumps(codon2freq))\n",
    "    \n",
    "with open(\"matrix-jsons/aa2aa2freq.json\", \"w\") as dumpster:\n",
    "    dumpster.write(json.dumps(aa2aa2freq))\n",
    "\n",
    "with open(\"matrix-jsons/aa2freq.json\", \"w\") as dumpster:\n",
    "    dumpster.write(json.dumps(aa2freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiime2-2021.2)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
