{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute read co-occurrence data for phasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T23:22:09.958489Z",
     "iopub.status.busy": "2021-06-11T23:22:09.957309Z",
     "iopub.status.idle": "2021-06-11T23:22:28.315311Z",
     "shell.execute_reply": "2021-06-11T23:22:28.314407Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T23:22:28.320160Z",
     "iopub.status.busy": "2021-06-11T23:22:28.319357Z",
     "iopub.status.idle": "2021-06-11T23:22:29.401432Z",
     "shell.execute_reply": "2021-06-11T23:22:29.400778Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pysam\n",
    "import skbio\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from linked_mutations_utils import find_mutated_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each read, identify all nucleotides aligned to mutated positions spanned by this read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T23:22:29.422853Z",
     "iopub.status.busy": "2021-06-11T23:22:29.420802Z",
     "iopub.status.idle": "2021-06-12T03:32:55.838522Z",
     "shell.execute_reply": "2021-06-12T03:32:55.837655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying mutated positions in genome CAMP...\n",
      "Found 283 mutated positions in CAMP.\n",
      "Going through these positions...\n",
      "\tOn aln 1000 in seq CAMP. Time spent on CAMP so far: 1.96 sec.\n",
      "Identifying mutated positions in genome BACT1...\n",
      "Found 23,971 mutated positions in BACT1.\n",
      "Going through these positions...\n",
      "\tOn aln 1000 in seq BACT1. Time spent on BACT1 so far: 1.92 sec.\n",
      "Identifying mutated positions in genome BACT2...\n",
      "Found 1,631 mutated positions in BACT2.\n",
      "Going through these positions...\n",
      "\tOn aln 1000 in seq BACT2. Time spent on BACT2 so far: 2.16 sec.\n",
      "Time taken: 53.520060539245605 sec.\n"
     ]
    }
   ],
   "source": [
    "bf = pysam.AlignmentFile(\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "\n",
    "# This probably won't save a noticeable amount of memory, but humor me\n",
    "i2n = \"ACGT\"\n",
    "n2i = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "\n",
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    fasta = skbio.DNA.read(\"../seqs/{}.fasta\".format(seq))\n",
    "    \n",
    "    # Identify all mutated positions in this genome up front to save time.\n",
    "    print(f\"Identifying mutated positions in genome {seq2name[seq]}...\")\n",
    "    mutated_positions = find_mutated_positions(seq)\n",
    "    print(f\"Found {len(mutated_positions):,} mutated positions in {seq2name[seq]}.\")\n",
    "    print(\"Going through these positions...\")\n",
    "    \n",
    "    # This should already be implicitly sorted, I think, but the code below relies on mutated_positions being\n",
    "    # in the exact same order as expected. So we may as well be paranoid.\n",
    "    mutated_positions = sorted(mutated_positions)\n",
    "    \n",
    "    # Maps read name to another dict of mutated position -> aligned nucleotide (in A, C, G, T).\n",
    "    # We build this up all at once so that we can take supplementary alignments of the same read into account.\n",
    "    readname2mutpos2nt = defaultdict(dict)\n",
    "    \n",
    "    # Go through all linear alignments of each read to this genome...\n",
    "    ts1 = time.time()\n",
    "    for ai, aln in enumerate(bf.fetch(seq), 1):\n",
    "        if ai % 1000 == 0:\n",
    "            print(\n",
    "                f\"\\tOn aln {ai:,} in seq {seq2name[seq]}. \"\n",
    "                f\"Time spent on {seq2name[seq]} so far: {time.time() - ts1:,.2f} sec.\"\n",
    "            )\n",
    "        ap = aln.get_aligned_pairs(matches_only=True)\n",
    "        \n",
    "        # Iterating through the aligned pairs is expensive. Since read lengths are generally in the thousands\n",
    "        # to tens of thousands of bp (which is much less than the > 1 million bp length of any bacterial genome),\n",
    "        # we set things up so that we only iterate through the aligned pairs once. We maintain an integer, mpi,\n",
    "        # that is a poor man's \"pointer\" to an index in mutated_positions.\n",
    "        \n",
    "        mpi = 0\n",
    "        \n",
    "        # Go through this aln's aligned pairs. As we see each pair, compare the pair's reference position\n",
    "        # (refpos) to the mpi-th mutated position (herein referred to as \"mutpos\").\n",
    "        #\n",
    "        # If refpos >  mutpos, increment mpi until refpos <= mutpos (stopping as early as possible).\n",
    "        # If refpos == mutpos, we have a match! Update readname2mutpos2ismutated[mutpos] based on\n",
    "        #                      comparing the read to the reference at the aligned positions.\n",
    "        # If refpos <  mutpos, continue to the next pair.\n",
    "        \n",
    "        readname = aln.query_name\n",
    "        for pair in ap:\n",
    "            \n",
    "            refpos = pair[1]\n",
    "            mutpos = mutated_positions[mpi]\n",
    "            \n",
    "            no_mutations_to_right_of_here = False\n",
    "            \n",
    "            # Increment mpi until we get to the next mutated position at or after the reference pos for this\n",
    "            # aligned pair (or until we run out of mutated positions).\n",
    "            while refpos > mutpos:\n",
    "                mpi += 1\n",
    "                if mpi < len(mutated_positions):\n",
    "                    mutpos = mutated_positions[mpi]\n",
    "                else:\n",
    "                    no_mutations_to_right_of_here = True\n",
    "                    break\n",
    "            \n",
    "            # I expect this should happen only for reads aligned near the right end of the genome.\n",
    "            if no_mutations_to_right_of_here:\n",
    "                break\n",
    "            \n",
    "            # If the next mutation occurs after this aligned pair, continue on to a later pair.\n",
    "            if refpos < mutpos:\n",
    "                continue\n",
    "                \n",
    "            # If we've made it here, refpos == mutpos!\n",
    "            # (...unless I messed something up in how I designed this code.)\n",
    "            if refpos != mutpos:\n",
    "                raise ValueError(\"This should never happen!\")\n",
    "                \n",
    "            # Finally, get the nucleotide aligned to this mutated position from this read.\n",
    "            readpos = pair[0]\n",
    "            # (Convert the nucleotide to an integer in the range [0, 3] using n2i)\n",
    "            readval = n2i[aln.query_sequence[readpos]]\n",
    "            \n",
    "            # Record this specific \"allele\" for this read. We can use this to link alleles that co-occur\n",
    "            # on the same read.\n",
    "            readname2mutpos2nt[readname][mutpos] = readval\n",
    "            \n",
    "    with open(f\"phasing-data/{seq}_readname2mutpos2nt.pickle\", \"wb\") as dumpster:\n",
    "        dumpster.write(pickle.dumps(readname2mutpos2nt))\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the numbers of reads supporting each observed combination of nucleotides at each pair of mutated positions spanned by at least _minSpan_ reads\n",
    "\n",
    "TODO: Load the pickled dicts you just output, so this step can be done independently of the previous one.\n",
    "\n",
    "We could use Hansel to store this data, but I opted to use a custom solution (for now, at least) for a few reasons:\n",
    "\n",
    "1. Don't need anything fancy -- just need to store this, not use the probabilistic weighting stuff\n",
    "2. I don't have time right now to learn Hansel's API (I've read through the docs and am still a bit confused)\n",
    "3. I think we could probably use less storage (e.g. we only need to store one \"triangle\" of the matrix; as far as I can tell, Hansel treats H\\[a, b, i, j\\] as independent of H\\[b, a, j, i\\], which isn't desirable for haplotyping IMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Now we've seen all alignments of each read, we can go through readname2mutpos2nt and compute co-occurrence\n",
    "#     # information (and create a graph, plot stuff, etc.)\n",
    "#     for readname in readname2mutpos2nt:\n",
    "#         mutated_positions_covered_in_read = readname2mutpos2nt[readname].keys()\n",
    "#         # Now that we've seen all mutated positions covered by this read, update pair information.\n",
    "        \n",
    "#         for (ii, jj) in combinations(mutated_positions_covered_in_read, 2):\n",
    "            \n",
    "#             # To make life easier, just sort the pair and save that as i and j.\n",
    "#             # I *think* we could sort mutated_positions_covered_in_read and then combinations() should\n",
    "#             # automatically generate sorted combinations, but I'm not sure if that is guaranteed -- so to\n",
    "#             # reduce the probability of weird bugs we can just sort things here.\n",
    "#             i, j = sorted([ii, jj])\n",
    "            \n",
    "#             # See if i and j are close enough to each other. There are two ways this can happen (these aren't\n",
    "#             # necessarily mutually exclusive but in practice probs will be, depending on genome size and\n",
    "#             # MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE)\n",
    "#             #\n",
    "#             # 1. i and j are close to each other without looping around the genome\n",
    "#             #    (e.g. i = 15,000; j = 15,001)\n",
    "#             #\n",
    "#             # 2. i and j are close to each other when you loop around the genome\n",
    "#             #    (e.g. genome length = 1,000,000; i = 0; j = 999,999)\n",
    "#             #    This case is only allowed when seq2iscircular[seq] is True. (For edges that aren't circular --\n",
    "#             #    e.g. edge 6104 [CAMP], as of writing, which is a linear edge within a circular component --\n",
    "#             #    we don't allow this case to ever be True.)\n",
    "            \n",
    "#             # Case 1\n",
    "#             close_enough_nolooping = (j - i) < MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE\n",
    "            \n",
    "#             # Case 2\n",
    "#             if seq2iscircular[seq]:\n",
    "#                 close_enough_looping = (seq2len[seq] + i - j) < MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE\n",
    "#             else:\n",
    "#                 close_enough_looping = False\n",
    "                \n",
    "#             if close_enough_nolooping or close_enough_looping:\n",
    "#                 im = readname2mutpos2ismutated[readname][i]\n",
    "#                 jm = readname2mutpos2ismutated[readname][j]\n",
    "#                 if im:\n",
    "#                     if jm:\n",
    "#                         # Read supports mutations at both i and j\n",
    "#                         pospair2groupcts[(i, j)][0] += 1\n",
    "#                     else:\n",
    "#                         # Read supports a mutation at i but not j\n",
    "#                         pospair2groupcts[(i, j)][1] += 1\n",
    "#                 else:\n",
    "#                     if jm:\n",
    "#                         # Read supports a mutation at j but not i\n",
    "#                         pospair2groupcts[(i, j)][2] += 1\n",
    "#                     else:\n",
    "#                         # Read doesn't support mutations at either i or j\n",
    "#                         pospair2groupcts[(i, j)][3] += 1\n",
    "\n",
    "#     print(f\"Finished going through reads in {seq2name[seq]}.\")\n",
    "    \n",
    "#     # Write out pospair2json to a safe location, just because this is probably going to take a while\n",
    "#     # and I don't want to risk losing this work.\n",
    "#     #\n",
    "#     # We use pickle instead of JSON because JSON can't handle tuples as the index of pospair2json:\n",
    "#     # see https://stackoverflow.com/a/16439720.\n",
    "#     # \n",
    "#     # We use the file suffix \".pickle\" and \"wb\" based on the conventions described in\n",
    "#     # https://stackoverflow.com/a/40433504 (...which in turn just reference the python docs).\n",
    "    \n",
    "#     with open(f\"pospair2groupcts/{seq}_pospair2groupcts.pickle\", \"wb\") as dumpster:\n",
    "#         dumpster.write(pickle.dumps(pospair2groupcts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
