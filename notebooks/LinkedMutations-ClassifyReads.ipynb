{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify reads covering close-by positions into four groups\n",
    "\n",
    "**Part 1 of the \"linked mutations\" analyses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T23:22:09.958489Z",
     "iopub.status.busy": "2021-06-11T23:22:09.957309Z",
     "iopub.status.idle": "2021-06-11T23:22:28.315311Z",
     "shell.execute_reply": "2021-06-11T23:22:28.314407Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T23:22:28.320160Z",
     "iopub.status.busy": "2021-06-11T23:22:28.319357Z",
     "iopub.status.idle": "2021-06-11T23:22:29.401432Z",
     "shell.execute_reply": "2021-06-11T23:22:29.400778Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pysam\n",
    "import skbio\n",
    "import hansel\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from linked_mutations_utils import find_mutated_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T23:22:29.422853Z",
     "iopub.status.busy": "2021-06-11T23:22:29.420802Z",
     "iopub.status.idle": "2021-06-12T03:32:55.838522Z",
     "shell.execute_reply": "2021-06-12T03:32:55.837655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying mutated positions in genome CAMP...\n",
      "Found 283 mutated positions in CAMP.\n",
      "Going through these positions...\n",
      "\tOn aln 1000 in seq CAMP. Time spent on CAMP so far: 1.91 sec.\n",
      "\tOn aln 2000 in seq CAMP. Time spent on CAMP so far: 3.55 sec.\n",
      "\tOn aln 3000 in seq CAMP. Time spent on CAMP so far: 5.41 sec.\n",
      "\tOn aln 4000 in seq CAMP. Time spent on CAMP so far: 7.08 sec.\n",
      "\tOn aln 5000 in seq CAMP. Time spent on CAMP so far: 9.22 sec.\n",
      "\tOn aln 6000 in seq CAMP. Time spent on CAMP so far: 12.31 sec.\n",
      "\tOn aln 7000 in seq CAMP. Time spent on CAMP so far: 15.35 sec.\n",
      "\tOn aln 8000 in seq CAMP. Time spent on CAMP so far: 18.45 sec.\n",
      "\tOn aln 9000 in seq CAMP. Time spent on CAMP so far: 21.61 sec.\n",
      "\tOn aln 10000 in seq CAMP. Time spent on CAMP so far: 24.67 sec.\n",
      "\tOn aln 11000 in seq CAMP. Time spent on CAMP so far: 27.79 sec.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-09deb64da09c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mrefpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mmutpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutated_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmpi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mno_mutations_to_right_of_here\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bf = pysam.AlignmentFile(\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "\n",
    "# This probably won't save a noticeable amount of memory, but humor me\n",
    "i2n = \"ACGT\"\n",
    "n2i = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "\n",
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    fasta = skbio.DNA.read(\"../seqs/{}.fasta\".format(seq))\n",
    "    \n",
    "    # Identify all mutated positions in this genome up front to save time.\n",
    "    print(f\"Identifying mutated positions in genome {seq2name[seq]}...\")\n",
    "    mutated_positions = find_mutated_positions(seq)\n",
    "    print(f\"Found {len(mutated_positions):,} mutated positions in {seq2name[seq]}.\")\n",
    "    print(\"Going through these positions...\")\n",
    "    \n",
    "    # This should already be implicitly sorted, I think, but the code below relies on mutated_positions being\n",
    "    # in the exact same order as expected. So we may as well be paranoid.\n",
    "    mutated_positions = sorted(mutated_positions)\n",
    "    \n",
    "    # Count the occurrences of each nucleotide (A, C, G, T) at each mutated position.\n",
    "    # These are stored at positions 0, 1, 2, 3 in these lists, as you might expect.\n",
    "    # This is a somewhat inefficient way of storing this data since there will be a lot of zeroes, probably,\n",
    "    # but speed is not our primary focus right now (translation: please I am so tired)\n",
    "    mp2nts = {mp: [0, 0, 0, 0] for mp in mutated_positions}\n",
    "    \n",
    "    # Maps read name to another dict of mutated position -> aligned nucleotide (in A, C, G, T).\n",
    "    # We build this up all at once so that we can take supplementary alignments of the same read into account.\n",
    "    readname2mutpos2nt = defaultdict(dict)\n",
    "    \n",
    "    # Go through all linear alignments of each read to this genome...\n",
    "    ts1 = time.time()\n",
    "    for ai, aln in enumerate(bf.fetch(seq), 1):\n",
    "        if ai % 1000 == 0:\n",
    "            print(\n",
    "                f\"\\tOn aln {ai} in seq {seq2name[seq]}. \"\n",
    "                f\"Time spent on {seq2name[seq]} so far: {time.time() - ts1:,.2f} sec.\"\n",
    "            )\n",
    "        ap = aln.get_aligned_pairs(matches_only=True)\n",
    "        \n",
    "        # Iterating through the aligned pairs is expensive. Since read lengths are generally in the thousands\n",
    "        # to tens of thousands of bp (which is much less than the > 1 million bp length of any bacterial genome),\n",
    "        # we set things up so that we only iterate through the aligned pairs once. We maintain an integer, mpi,\n",
    "        # that is a poor man's \"pointer\" to an index in mutated_positions.\n",
    "        \n",
    "        mpi = 0\n",
    "        \n",
    "        # Go through this aln's aligned pairs. As we see each pair, compare the pair's reference position\n",
    "        # (refpos) to the mpi-th mutated position (herein referred to as \"mutpos\").\n",
    "        #\n",
    "        # If refpos >  mutpos, increment mpi until refpos <= mutpos (stopping as early as possible).\n",
    "        # If refpos == mutpos, we have a match! Update readname2mutpos2ismutated[mutpos] based on\n",
    "        #                      comparing the read to the reference at the aligned positions.\n",
    "        # If refpos <  mutpos, continue to the next pair.\n",
    "        \n",
    "        readname = aln.query_name\n",
    "        for pair in ap:\n",
    "            \n",
    "            refpos = pair[1]\n",
    "            mutpos = mutated_positions[mpi]\n",
    "            \n",
    "            no_mutations_to_right_of_here = False\n",
    "            \n",
    "            # Increment mpi until we get to the next mutated position at or after the reference pos for this\n",
    "            # aligned pair (or until we run out of mutated positions).\n",
    "            while refpos > mutpos:\n",
    "                mpi += 1\n",
    "                if mpi < len(mutated_positions):\n",
    "                    mutpos = mutated_positions[mpi]\n",
    "                else:\n",
    "                    no_mutations_to_right_of_here = True\n",
    "                    break\n",
    "            \n",
    "            # I expect this should happen only for reads aligned near the right end of the genome.\n",
    "            if no_mutations_to_right_of_here:\n",
    "                break\n",
    "            \n",
    "            # If the next mutation occurs after this aligned pair, continue on to a later pair.\n",
    "            if refpos < mutpos:\n",
    "                continue\n",
    "                \n",
    "            # If we've made it here, refpos == mutpos!\n",
    "            # (...unless I messed something up in how I designed this code.)\n",
    "            if refpos != mutpos:\n",
    "                raise ValueError(\"This should never happen!\")\n",
    "                \n",
    "            # Finally, get the nucleotide aligned to this mutated position from this read.\n",
    "            readpos = pair[0]\n",
    "            # (Convert the nucleotide to an integer in the range [0, 23] using n2i)\n",
    "            readval = n2i[aln.query_sequence[readpos]]\n",
    "            \n",
    "            # Record this specific \"allele\" for this read. We can use this to link alleles that co-occur\n",
    "            # on the same read. \n",
    "            readname2mutpos2nt[readname][mutpos] = readval\n",
    "            \n",
    "            # Update numbers of nucleotides seen at this mutated position. This is reads(i, N), as described\n",
    "            # in the paper.\n",
    "            mp2nts[mutpos][readval] += 1\n",
    "            \n",
    "            # (For debugging -- this is the first \"highly mutated\" position in G1217, the binary CAMP gene)\n",
    "            # if mutpos == 1209000:\n",
    "            #    text += (f\"{aln.query_name} @ {refpos}. ref = {refval}, read = {readval}\")\n",
    "        \n",
    "        \n",
    "#     # Now we've seen all alignments of each read.\n",
    "#     for readname in readname2mutpos2nt:\n",
    "#         mutated_positions_covered_in_read = readname2mutpos2nt[readname].keys()\n",
    "#         # Now that we've seen all mutated positions covered by this read, update pair information.\n",
    "        \n",
    "#         for (ii, jj) in combinations(mutated_positions_covered_in_read, 2):\n",
    "            \n",
    "#             # To make life easier, just sort the pair and save that as i and j.\n",
    "#             # I *think* we could sort mutated_positions_covered_in_read and then combinations() should\n",
    "#             # automatically generate sorted combinations, but I'm not sure if that is guaranteed -- so to\n",
    "#             # reduce the probability of weird bugs we can just sort things here.\n",
    "#             i, j = sorted([ii, jj])\n",
    "            \n",
    "#             # See if i and j are close enough to each other. There are two ways this can happen (these aren't\n",
    "#             # necessarily mutually exclusive but in practice probs will be, depending on genome size and\n",
    "#             # MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE)\n",
    "#             #\n",
    "#             # 1. i and j are close to each other without looping around the genome\n",
    "#             #    (e.g. i = 15,000; j = 15,001)\n",
    "#             #\n",
    "#             # 2. i and j are close to each other when you loop around the genome\n",
    "#             #    (e.g. genome length = 1,000,000; i = 0; j = 999,999)\n",
    "#             #    This case is only allowed when seq2iscircular[seq] is True. (For edges that aren't circular --\n",
    "#             #    e.g. edge 6104 [CAMP], as of writing, which is a linear edge within a circular component --\n",
    "#             #    we don't allow this case to ever be True.)\n",
    "            \n",
    "#             # Case 1\n",
    "#             close_enough_nolooping = (j - i) < MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE\n",
    "            \n",
    "#             # Case 2\n",
    "#             if seq2iscircular[seq]:\n",
    "#                 close_enough_looping = (seq2len[seq] + i - j) < MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE\n",
    "#             else:\n",
    "#                 close_enough_looping = False\n",
    "                \n",
    "#             if close_enough_nolooping or close_enough_looping:\n",
    "#                 im = readname2mutpos2ismutated[readname][i]\n",
    "#                 jm = readname2mutpos2ismutated[readname][j]\n",
    "#                 if im:\n",
    "#                     if jm:\n",
    "#                         # Read supports mutations at both i and j\n",
    "#                         pospair2groupcts[(i, j)][0] += 1\n",
    "#                     else:\n",
    "#                         # Read supports a mutation at i but not j\n",
    "#                         pospair2groupcts[(i, j)][1] += 1\n",
    "#                 else:\n",
    "#                     if jm:\n",
    "#                         # Read supports a mutation at j but not i\n",
    "#                         pospair2groupcts[(i, j)][2] += 1\n",
    "#                     else:\n",
    "#                         # Read doesn't support mutations at either i or j\n",
    "#                         pospair2groupcts[(i, j)][3] += 1\n",
    "\n",
    "#     print(f\"Finished going through reads in {seq2name[seq]}.\")\n",
    "    \n",
    "#     # Write out pospair2json to a safe location, just because this is probably going to take a while\n",
    "#     # and I don't want to risk losing this work.\n",
    "#     #\n",
    "#     # We use pickle instead of JSON because JSON can't handle tuples as the index of pospair2json:\n",
    "#     # see https://stackoverflow.com/a/16439720.\n",
    "#     # \n",
    "#     # We use the file suffix \".pickle\" and \"wb\" based on the conventions described in\n",
    "#     # https://stackoverflow.com/a/40433504 (...which in turn just reference the python docs).\n",
    "    \n",
    "#     with open(f\"pospair2groupcts/{seq}_pospair2groupcts.pickle\", \"wb\") as dumpster:\n",
    "#         dumpster.write(pickle.dumps(pospair2groupcts))\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
