{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify and cluster \"linked\" mutated positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T13:06:36.967391Z",
     "iopub.status.busy": "2021-04-12T13:06:36.966453Z",
     "iopub.status.idle": "2021-04-12T13:06:37.229248Z",
     "shell.execute_reply": "2021-04-12T13:06:37.228218Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\"\n",
    "%run \"LoadMutationJSONData.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-12T13:06:54.763033Z",
     "iopub.status.busy": "2021-04-12T13:06:54.762235Z",
     "iopub.status.idle": "2021-04-12T13:06:55.823302Z",
     "shell.execute_reply": "2021-04-12T13:06:55.822354Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pysam\n",
    "import skbio\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define various constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unless (pos j) - (pos i) < this, we do not consider i and j linked.\n",
    "MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE = 3000\n",
    "\n",
    "# unless at least this many reads have mutations at both pos i and pos j, we do not consider i and j linked.\n",
    "MIN_COV_OF_MUTATIONS_AT_LINKED_POSITIONS = 1000\n",
    "\n",
    "# unless |Reads(i, -)| + |Reads(-, j)| < this fraction * |Reads(i, j)|, we do not consider i and j linked.\n",
    "MAX_NONLINKED_MUTATED_FRACTION_NONINCLUSIVE = 0.2\n",
    "\n",
    "# How we call a mutation: only if (# mismatches) / (# mismatches + # matches) > MINFREQ.\n",
    "# Defaults to 0.5%.\n",
    "MINFREQ = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify reads covering close-by positions into four groups\n",
    "\n",
    "See the section of the paper on linked positions for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pysam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-680388ca2bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0memptyListOf4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pysam' is not defined"
     ]
    }
   ],
   "source": [
    "bf = pysam.AlignmentFile(\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "\n",
    "# Used to initialize entries in the pospair2groupcts defaultdict below.\n",
    "# This was originally a lambda function, but that breaks pickle: https://stackoverflow.com/a/16439720\n",
    "# ... so we need to use an ordinary function instead.\n",
    "def emptyListOf4():\n",
    "    return [0, 0, 0, 0]\n",
    "\n",
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    fasta = skbio.DNA.read(\"../seqs/{}.fasta\".format(seq))\n",
    "    # Maps tuple of (left integer pos, right integer pos) to a list of [0, 0, 0, 0].\n",
    "    # (Since a pair (i, j) is equal to a pair (j, i), we just index this so that the leftmost position is the\n",
    "    # first element in the tuple and the rightmost position is the second element. This seems like a more intuitive\n",
    "    # way of structuring this then as a nested dict of leftpos2rightpos2groupcts.)\n",
    "    # https://stackoverflow.com/a/13065439\n",
    "    #\n",
    "    # Each entry in the list indicates counts of types of reads connecting these two positions we've seen thus\n",
    "    # far. In 0-indexed coordinates:\n",
    "    #\n",
    "    # 0. Reads(i, j): reads that support mutations at both positions\n",
    "    # 1. Reads(i, -): reads that only support mutations at i\n",
    "    # 2. Reads(-, j): reads that only support mutations at j\n",
    "    # 3. Reads(-, -): reads that do not support mutations at either position\n",
    "    #\n",
    "    # This matches the definitions in the paper (currently that is section 3.6.2, but that number may change as\n",
    "    # the paper is edited and restructured).\n",
    "    \n",
    "    pospair2groupcts = defaultdict(emptyListOf4)\n",
    "    \n",
    "    # Identify all mutated positions in this genome up front to save time.\n",
    "    print(f\"Identifying mutated positions in genome {seq2name[seq]}...\")\n",
    "    mutated_positions = []\n",
    "    for pos in seq2pos2matchct[seq].keys():\n",
    "        \n",
    "        matchct = seq2pos2matchct[seq][pos]\n",
    "        mismatchct = seq2pos2mismatchct[seq][pos]\n",
    "        cov = mismatchct + matchct\n",
    "        \n",
    "        # We can be strict and filter out positions that don't pass the coverage filter for linked reads -- no\n",
    "        # sense including these.\n",
    "        if cov >= MIN_COV_OF_MUTATIONS_AT_LINKED_POSITIONS:\n",
    "            \n",
    "            # Actually \"call\" mutations, the same way we do elsewhere in these analyses (albeit maybe with\n",
    "            # different values of MINFREQ). Of course, this isn't the only way to do this.\n",
    "            if (mismatchct / cov) > MINFREQ:\n",
    "                mutated_positions.append(int(pos))\n",
    "    print(f\"Found {len(mutated_positions)} mutated positions in {seq2name[seq]}.\")\n",
    "    \n",
    "    # This should already be implicitly sorted, I think, but the code below relies on mutated_positions being\n",
    "    # in the exact same order as expected. So we may as well be paranoid.\n",
    "    mutated_positions = sorted(mutated_positions)\n",
    "    \n",
    "    # Go through all aligned segments for this genome...\n",
    "    ts1 = time.time()\n",
    "    for ri, read in enumerate(bf.fetch(seq), 1):\n",
    "        if ri % 100 == 0:\n",
    "            print(f\"On read {ri} in seq {seq2name[seq]}. Time spent so far: {time.time() - ts1:.2f} sec.\")\n",
    "        ap = read.get_aligned_pairs(matches_only=True)\n",
    "        \n",
    "        # Maps mutated positions seen in this segment to True (this read is mutated at this position, compared\n",
    "        # to the reference) or False (this read is not mutated at this position, compared to the reference).\n",
    "        # The absence of a mutated position from this dict implies that this position is not seen in this aligned\n",
    "        # segment (either due to indels/skips or this read just not being aligned to cover it).\n",
    "        #\n",
    "        # After we compute this we can increment pospair2groupcts accordingly for every pair of mutated positions\n",
    "        # present in this dict.\n",
    "        mutpos2ismutated = {}\n",
    "        \n",
    "        # Iterating through the aligned pairs is expensive. Since read lengths are generally in the thousands\n",
    "        # to tens of thousands of bp (which is much less than the > 1 million bp length of any bacterial genome),\n",
    "        # we set things up so that we only iterate through the aligned pairs once. We maintain an integer, mpi,\n",
    "        # that is a poor man's \"pointer\" to an index in mutated_positions.\n",
    "        \n",
    "        mpi = 0\n",
    "        \n",
    "        # Go through this read's aligned pairs. As we see each pair, compare the pair's reference position\n",
    "        # (refpos) to the mpi-th mutated position (herein referred to as \"mutpos\").\n",
    "        #\n",
    "        # If refpos >  mutpos, increment mpi until refpos <= mutpos (stopping as early as possible).\n",
    "        # If refpos == mutpos, we have a match! Update mutpos2ismutated[mutpos] based on comparing this read's\n",
    "        #                      aligned value at this position to the reference at this position.\n",
    "        # If refpos <  mutpos, continue to the next pair.\n",
    "        \n",
    "        # After doing all that, we can just use mutpos2ismutated to update the group counts for each pair.\n",
    "        \n",
    "        mutated_positions_covered_in_read = []\n",
    "        \n",
    "        for pair in ap:\n",
    "            \n",
    "            refpos = pair[1]\n",
    "            mutpos = mutated_positions[mpi]\n",
    "            \n",
    "            no_mutations_to_right_of_here = False\n",
    "            \n",
    "            # Increment mpi until we get to the next mutated position at or after the reference pos for this\n",
    "            # aligned pair (or until we run out of mutated positions).\n",
    "            while refpos > mutpos:\n",
    "                mpi += 1\n",
    "                if mpi < len(mutated_positions):\n",
    "                    mutpos = mutated_positions[mpi]\n",
    "                else:\n",
    "                    no_mutations_to_right_of_here = True\n",
    "                    break\n",
    "            \n",
    "            # I expect this should happen only for reads aligned near the right end of the genome.\n",
    "            if no_mutations_to_right_of_here:\n",
    "                break\n",
    "            \n",
    "            # If the next mutation occurs after this aligned pair, continue on to a later pair.\n",
    "            if refpos < mutpos:\n",
    "                continue\n",
    "                \n",
    "            # If we've made it here, refpos == mutpos!\n",
    "            # (...unless I messed something up in how I designed this code.)\n",
    "            if refpos != mutpos:\n",
    "                raise ValueError(\"This should never happen!\")\n",
    "                \n",
    "            # Finally, compare the read to the reference at this position, and update mutpos2ismutated.\n",
    "            readpos = pair[0]\n",
    "            \n",
    "            # WE NEED TO CONVERT TO A STRING because slicing a skbio.DNA object returns another DNA object.\n",
    "            # May or may not have spent an hour staring at the screen due to that ._.\n",
    "            refval = str(fasta[refpos])\n",
    "            readval = read.query_sequence[readpos]\n",
    "            \n",
    "            mutated = (readval != refval)\n",
    "            \n",
    "            # if mutated:\n",
    "            #     print(f\"Read {read.query_name} at pos {refpos}. ref = {refval}, read = {readval}, mutated = {mutated}\")\n",
    "            \n",
    "            mutpos2ismutated[mutpos] = mutated\n",
    "                \n",
    "            mutated_positions_covered_in_read.append(mutpos)\n",
    "        \n",
    "        # Now that we've seen all mutated positions covered by this read, update pair information.\n",
    "        # The naive way to do this is to iterate over\n",
    "        # itertools.combinations(mutated_positions_covered_by_read, 2) -- however, that is super expensive\n",
    "        # for even relatively small numbers of positions (5000 choose 2 is almost 12.5 million!)\n",
    "        #\n",
    "        # We can save time and effort by using a few tricks to only consider subsets of these pairs corresponding\n",
    "        # to close-together mutated positions (within the max distance btwn linked positions).\n",
    "        #\n",
    "        # For each mutated position...\n",
    "        for pindex, pi in enumerate(mutated_positions_covered_in_read, 0):\n",
    "\n",
    "            # For each mutated position located to the right of this one:\n",
    "            # (If pi is the last mutated position, then slicing by [pindex + 1:] will just return an empty list\n",
    "            # and we will implicitly skip the entire body of the for loop below here.)\n",
    "            for pj in mutated_positions_covered_in_read[pindex + 1:]:\n",
    "\n",
    "                # No need to take abs(), since we know pi < pj.\n",
    "                if pj - pi < MAX_DIST_BTWN_LINKED_POSITIONS_NONINCLUSIVE:\n",
    "                    piv = mutpos2ismutated[pi]\n",
    "                    pjv = mutpos2ismutated[pj]\n",
    "                    if piv:\n",
    "                        if pjv:\n",
    "                            # Read supports mutations at both i and j\n",
    "                            pospair2groupcts[(pi, pj)][0] += 1\n",
    "                        else:\n",
    "                            # Read supports a mutation at i but not j\n",
    "                            pospair2groupcts[(pi, pj)][1] += 1\n",
    "                    else:\n",
    "                        if pjv:\n",
    "                            # Read supports a mutation at j but not i\n",
    "                            pospair2groupcts[(pi, pj)][2] += 1\n",
    "                        else:\n",
    "                            # Read doesn't support mutations at either i or j\n",
    "                            pospair2groupcts[(pi, pj)][3] += 1\n",
    "                    \n",
    "                else:\n",
    "                    # Since mutated_positions is monotonically increasing (...it's a sorted list of positions),\n",
    "                    # we can break as soon as we get to the max distance away from p1.\n",
    "                    break\n",
    "\n",
    "    print(f\"Finished going through reads in {seq2name[seq]}.\")\n",
    "    \n",
    "    # Write out pospair2json to a safe location, just because this is probably going to take a while\n",
    "    # and I don't want to risk losing this work.\n",
    "    #\n",
    "    # We use pickle instead of JSON because JSON can't handle tuples as the index of pospair2json:\n",
    "    # see https://stackoverflow.com/a/16439720.\n",
    "    # \n",
    "    # We use the file suffix \".pickle\" and \"wb\" based on the conventions described in\n",
    "    # https://stackoverflow.com/a/40433504 (...which in turn just reference the python docs).\n",
    "    \n",
    "    with open(f\"tmp/{seq}_pospair2groupcts.pickle\", \"wb\") as dumpster:\n",
    "        dumpster.write(pickle.dumps(pospair2groupcts))\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the computed groups, define mutated positions as \"linked\" or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiime2-2021.2)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
