{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute \"link graph\" for phasing\n",
    "\n",
    "This'll be continued in the next notebook, `Phasing-02-VizGraph.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:57.580024Z",
     "iopub.status.busy": "2021-10-16T02:49:57.578415Z",
     "iopub.status.idle": "2021-10-16T02:49:57.937571Z",
     "shell.execute_reply": "2021-10-16T02:49:57.936229Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:57.942682Z",
     "iopub.status.busy": "2021-10-16T02:49:57.941820Z",
     "iopub.status.idle": "2021-10-16T02:49:59.163970Z",
     "shell.execute_reply": "2021-10-16T02:49:59.164651Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pysam\n",
    "import skbio\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from linked_mutations_utils import find_mutated_positions, gen_ddi, MINSPAN, MINLINK_EXCLUSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:59.170296Z",
     "iopub.status.busy": "2021-10-16T02:49:59.169474Z",
     "iopub.status.idle": "2021-10-16T02:49:59.171605Z",
     "shell.execute_reply": "2021-10-16T02:49:59.172253Z"
    }
   },
   "outputs": [],
   "source": [
    "# This probably won't save a noticeable amount of memory, but humor me\n",
    "i2n = \"ACGT\"\n",
    "n2i = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. For each read, identify all nucleotides aligned to mutated positions spanned by this read\n",
    "\n",
    "This takes about 1.8 hours for the three selected genomes. (That said, these genomes have super high coverage, so for less-well-covered genomes this will probably go faster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:59.179723Z",
     "iopub.status.busy": "2021-10-16T02:49:59.178829Z",
     "iopub.status.idle": "2021-10-16T02:49:59.181967Z",
     "shell.execute_reply": "2021-10-16T02:49:59.181245Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bf = pysam.AlignmentFile(\"../main-workflow/output/fully-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "\n",
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    fasta = skbio.DNA.read(\"../seqs/{}.fasta\".format(seq))\n",
    "    \n",
    "    # Identify all mutated positions in this genome up front to save time.\n",
    "    print(f\"Identifying mutated positions in genome {seq2name[seq]}...\")\n",
    "    mutated_positions = find_mutated_positions(seq)\n",
    "    print(f\"Found {len(mutated_positions):,} mutated positions in {seq2name[seq]}.\")\n",
    "    print(\"Going through these positions...\")\n",
    "    \n",
    "    # This should already be implicitly sorted, I think, but the code below relies on mutated_positions being\n",
    "    # in the exact same order as expected. So we may as well be paranoid.\n",
    "    mutated_positions = sorted(mutated_positions)\n",
    "    \n",
    "    # Maps read name to another dict of mutated position -> aligned nucleotide (in A, C, G, T).\n",
    "    # We build this up all at once so that we can take supplementary alignments of the same read into account.\n",
    "    readname2mutpos2nt = defaultdict(dict)\n",
    "    \n",
    "    # Go through all linear alignments of each read to this genome...\n",
    "    ts1 = time.time()\n",
    "    for ai, aln in enumerate(bf.fetch(seq), 1):\n",
    "        if ai % 1000 == 0:\n",
    "            print(\n",
    "                f\"\\tOn aln {ai:,} in seq {seq2name[seq]}. \"\n",
    "                f\"Time spent on {seq2name[seq]} so far: {time.time() - ts1:,.2f} sec.\"\n",
    "            )\n",
    "        ap = aln.get_aligned_pairs(matches_only=True)\n",
    "        \n",
    "        # Iterating through the aligned pairs is expensive. Since read lengths are generally in the thousands\n",
    "        # to tens of thousands of bp (which is much less than the > 1 million bp length of any bacterial genome),\n",
    "        # we set things up so that we only iterate through the aligned pairs once. We maintain an integer, mpi,\n",
    "        # that is a poor man's \"pointer\" to an index in mutated_positions.\n",
    "        \n",
    "        mpi = 0\n",
    "        \n",
    "        # Go through this aln's aligned pairs. As we see each pair, compare the pair's reference position\n",
    "        # (refpos) to the mpi-th mutated position (herein referred to as \"mutpos\").\n",
    "        #\n",
    "        # If refpos >  mutpos, increment mpi until refpos <= mutpos (stopping as early as possible).\n",
    "        # If refpos == mutpos, we have a match! Update readname2mutpos2ismutated[mutpos] based on\n",
    "        #                      comparing the read to the reference at the aligned positions.\n",
    "        # If refpos <  mutpos, continue to the next pair.\n",
    "        \n",
    "        readname = aln.query_name\n",
    "        for pair in ap:\n",
    "            \n",
    "            refpos = pair[1]\n",
    "            mutpos = mutated_positions[mpi]\n",
    "            \n",
    "            no_mutations_to_right_of_here = False\n",
    "            \n",
    "            # Increment mpi until we get to the next mutated position at or after the reference pos for this\n",
    "            # aligned pair (or until we run out of mutated positions).\n",
    "            while refpos > mutpos:\n",
    "                mpi += 1\n",
    "                if mpi < len(mutated_positions):\n",
    "                    mutpos = mutated_positions[mpi]\n",
    "                else:\n",
    "                    no_mutations_to_right_of_here = True\n",
    "                    break\n",
    "            \n",
    "            # I expect this should happen only for reads aligned near the right end of the genome.\n",
    "            if no_mutations_to_right_of_here:\n",
    "                break\n",
    "            \n",
    "            # If the next mutation occurs after this aligned pair, continue on to a later pair.\n",
    "            if refpos < mutpos:\n",
    "                continue\n",
    "                \n",
    "            # If we've made it here, refpos == mutpos!\n",
    "            # (...unless I messed something up in how I designed this code.)\n",
    "            if refpos != mutpos:\n",
    "                raise ValueError(\"This should never happen!\")\n",
    "                \n",
    "            # Finally, get the nucleotide aligned to this mutated position from this read.\n",
    "            readpos = pair[0]\n",
    "            # (Convert the nucleotide to an integer in the range [0, 3] using n2i)\n",
    "            readval = n2i[aln.query_sequence[readpos]]\n",
    "            \n",
    "            # Record this specific \"allele\" for this read. We can use this to link alleles that co-occur\n",
    "            # on the same read.\n",
    "            readname2mutpos2nt[readname][mutpos] = readval\n",
    "            \n",
    "    with open(f\"phasing-data/{seq}_readname2mutpos2nt.pickle\", \"wb\") as dumpster:\n",
    "        dumpster.write(pickle.dumps(readname2mutpos2nt))\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1:,} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute frequency information for individual nucleotides and pairs of nucleotides at mutated positions\n",
    "\n",
    "We could use Hansel to store the pairs-of-nucleotides data as a matrix, but I opted to use a custom solution (for now, at least) for a few reasons:\n",
    "\n",
    "1. Don't need anything fancy -- just need to store this, not use the probabilistic weighting stuff\n",
    "2. I don't have time right now to learn Hansel's API (I've read through the docs and am still a bit confused)\n",
    "3. I think we could probably use less storage (e.g. we only need to store one \"triangle\" of the matrix; as far as I can tell, Hansel treats H\\[a, b, i, j\\] as independent of H\\[b, a, j, i\\], which isn't necessary for haplotyping IMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T02:49:59.194058Z",
     "iopub.status.busy": "2021-10-16T02:49:59.190344Z",
     "iopub.status.idle": "2021-10-16T03:50:30.131419Z",
     "shell.execute_reply": "2021-10-16T03:50:30.130656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348,612 unique reads described in the data for seq CAMP.\n",
      "\tOn read 100,000 in seq CAMP. Time spent on CAMP so far: 0.40 sec.\n",
      "\tOn read 200,000 in seq CAMP. Time spent on CAMP so far: 0.83 sec.\n",
      "\tOn read 300,000 in seq CAMP. Time spent on CAMP so far: 3.24 sec.\n",
      "Finished going through reads in CAMP.\n",
      "257,428 unique reads described in the data for seq BACT1.\n",
      "\tOn read 100,000 in seq BACT1. Time spent on BACT1 so far: 1,198.51 sec.\n",
      "\tOn read 200,000 in seq BACT1. Time spent on BACT1 so far: 2,807.78 sec.\n",
      "Finished going through reads in BACT1.\n",
      "700,066 unique reads described in the data for seq BACT2.\n",
      "\tOn read 100,000 in seq BACT2. Time spent on BACT2 so far: 6.45 sec.\n",
      "\tOn read 200,000 in seq BACT2. Time spent on BACT2 so far: 8.70 sec.\n",
      "\tOn read 300,000 in seq BACT2. Time spent on BACT2 so far: 10.09 sec.\n",
      "\tOn read 400,000 in seq BACT2. Time spent on BACT2 so far: 11.34 sec.\n",
      "\tOn read 500,000 in seq BACT2. Time spent on BACT2 so far: 12.47 sec.\n",
      "\tOn read 600,000 in seq BACT2. Time spent on BACT2 so far: 13.76 sec.\n",
      "\tOn read 700,000 in seq BACT2. Time spent on BACT2 so far: 24.12 sec.\n",
      "Finished going through reads in BACT2.\n",
      "Time taken: 3630.9314334392548 sec.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    with open(f\"phasing-data/{seq}_readname2mutpos2nt.pickle\", \"rb\") as loadster:\n",
    "        # NOTE: this won't necessarily include ALL reads aligned to a sequence -- for example, if a read\n",
    "        # doesn't cover any mutated positions, it will be omitted from the top level of this dict. (This is\n",
    "        # because these reads won't be useful for linking the mutated positions.)\n",
    "        readname2mutpos2nt = pickle.load(loadster)\n",
    "        print(f\"{len(readname2mutpos2nt):,} unique reads described in the data for seq {seq2name[seq]}.\")\n",
    "\n",
    "    ts1 = time.time()\n",
    "    \n",
    "    # Now we've seen all alignments of each read, we can go through readname2mutpos2nt and compute\n",
    "    # co-occurrence information (and create a graph, plot stuff, etc.)\n",
    "    \n",
    "    # Maps mutated position -> nucleotide seen at this position, summed across all reads included here -> freq.\n",
    "    # This corresponds to Reads(i, N) as described in the paper.\n",
    "    pos2nt2freq = defaultdict(gen_ddi)\n",
    "    \n",
    "    # This defaultdict has two levels:\n",
    "    # OUTER: Keys are sorted (in ascending order) 0-indexed pairs (tuples) of mutated positions. The\n",
    "    #        inclusion ofa pair of mutated positions in this defaultdict implies that these two mutated\n",
    "    #        positions were spanned by at least one read. The value of each pair is another defaultdict:\n",
    "    #\n",
    "    # INNER: The keys of this inner defaultdict are pairs of integers, each in the range [0, 3].\n",
    "    #        These represent the 4 nucleotides (0 -> A, 1 -> C, 2 -> G, 3 -> T): the first entry represents\n",
    "    #        the nucleotide seen at the first position in the pair (aka the position \"earlier\" in the genome),\n",
    "    #        and the second entry represents the nucleotide seen at the second position in the pair (aka\n",
    "    #        the position \"later\" in the genome). Of course, many bacterial genomes are circular, so \"earlier\"\n",
    "    #        and \"later\" are kinda arbitrary. Anyway, there are 16 possible pairs in one of these defaultdicts,\n",
    "    #        since there are 4^2 = 16 different possible combinations of two nucleotides (ignoring deletions,\n",
    "    #        degenerate nucleotides, etc.) That said, I expect in practice only a handful of nucleotide pairs\n",
    "    #        will be present for a given position pair. The value of each pair in this defaultdict is\n",
    "    #        an integer representing the frequency with which this pair of nucleotides was observed on a\n",
    "    #        spanning read at this pair of positions.\n",
    "    #\n",
    "    # So, as an example, if we only have two mutated positions in a genome (at 0-indexed positions 100 and 500),\n",
    "    # and we saw:\n",
    "    #\n",
    "    # - 30    reads with an A at both positions\n",
    "    # - 1,000 reads with an A at position 100 and a T at position 500\n",
    "    # - 5     reads with a T at position 100 and an A at position 500\n",
    "    # - 100   reads with a T at both positions\n",
    "    # - 3     reads with a C at position 100 and a T at position 500\n",
    "    # - 1     read  with a G at position 100 and a T at position 500\n",
    "    #\n",
    "    # ... then pospair2ntpair2freq would look like\n",
    "    # {\n",
    "    #     (100, 500): {\n",
    "    #         {\n",
    "    #             (0, 0): 30,\n",
    "    #             (0, 3): 1000,\n",
    "    #             (3, 0): 5,\n",
    "    #             (3, 3): 100,\n",
    "    #             (1, 3): 3,\n",
    "    #             (2, 3): 1\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "    pospair2ntpair2freq = defaultdict(gen_ddi)\n",
    "    for ri, readname in enumerate(readname2mutpos2nt, 1):\n",
    "        if ri % 100000 == 0:\n",
    "            print(\n",
    "                f\"\\tOn read {ri:,} in seq {seq2name[seq]}. \"\n",
    "                f\"Time spent on {seq2name[seq]} so far: {time.time() - ts1:,.2f} sec.\"\n",
    "            )\n",
    "        # TODO: see if we can avoid sorting here -- inefficient when done once for every read, maybe?\n",
    "        mutated_positions_covered_in_read = sorted(readname2mutpos2nt[readname].keys())\n",
    "        \n",
    "        # NOTE: it may be possible to include this in the combinations() loop below, but we'd need some\n",
    "        # snazzy logic to prevent updating the same position multiple times. Easiest for my sanity to just\n",
    "        # be a bit inefficient and make this two separate loops.\n",
    "        for mutpos in mutated_positions_covered_in_read:\n",
    "            pos2nt2freq[mutpos][readname2mutpos2nt[readname][mutpos]] += 1\n",
    "            \n",
    "        for (i, j) in combinations(mutated_positions_covered_in_read, 2):\n",
    "            \n",
    "            # We can assume that i and j are sorted because mutated_positions_covered_in_read is sorted:\n",
    "            # see https://docs.python.org/3.10/library/itertools.html#itertools.combinations. This is\n",
    "            # guaranteed, but let's be paranoid just in case:\n",
    "            if j <= i:\n",
    "                raise ValueError(\"Something went horribly wrong with combinations()\")\n",
    "                \n",
    "            # these are integers in the range [0, 3]\n",
    "            i_nt = readname2mutpos2nt[readname][i]\n",
    "            j_nt = readname2mutpos2nt[readname][j]\n",
    "            \n",
    "            # We know these mutated positions were observed on the same read, and we know the exact nucleotides\n",
    "            # this read had at both positions -- update this in pospair2ntpair2freq\n",
    "            pospair2ntpair2freq[(i, j)][(i_nt, j_nt)] += 1\n",
    "            \n",
    "            # print(f\"Read {readname} has {i2n[i_nt]} at pos {i} and {i2n[j_nt]} at pos {j}.\")\n",
    "\n",
    "    print(f\"Finished going through reads in {seq2name[seq]}.\")\n",
    "    \n",
    "    # We use the file suffix \".pickle\" and \"wb\" based on the conventions described in\n",
    "    # https://stackoverflow.com/a/40433504 (...which in turn just reference the python docs).\n",
    "    with open(f\"phasing-data/{seq}_pospair2ntpair2freq.pickle\", \"wb\") as dumpster:\n",
    "        dumpster.write(pickle.dumps(pospair2ntpair2freq))\n",
    "        \n",
    "    with open(f\"phasing-data/{seq}_pos2nt2freq.pickle\", \"wb\") as dumpster:\n",
    "        dumpster.write(pickle.dumps(pos2nt2freq))\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1:,} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert position pair + nucleotide pair information to a graph structure\n",
    "\n",
    "We now know, for every pair of positions spanned by at least one read, the frequencies of nucleotide pairs seen together at these positions.\n",
    "\n",
    "We can now construct a graph where nodes represent _alleles_ (position + nucleotide seen at this position), and edges connect alleles seen together.\n",
    "\n",
    "We only connect two allele nodes if (ignoring exact nucleotides) at least _minSpan_ reads cover both positions, and the __link__ between two allele nodes (defined in the paper) is at least _minLink_. These parameters' values are given in `linked_mutations_utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:50:30.140151Z",
     "iopub.status.busy": "2021-10-16T03:50:30.139304Z",
     "iopub.status.idle": "2021-10-16T03:51:55.850088Z",
     "shell.execute_reply": "2021-10-16T03:51:55.849354Z"
    }
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "for seq in SEQS:\n",
    "    print(f\"Generating link graph for seq {seq}...\")\n",
    "    with open(f\"phasing-data/{seq}_pos2nt2freq.pickle\", \"rb\") as loadster:\n",
    "        pos2nt2freq = pickle.load(loadster)\n",
    "        \n",
    "    g = nx.Graph()\n",
    "    \n",
    "    # Add nodes to the graph -- one per seen nucleotide at every mutated position\n",
    "    for pos in pos2nt2freq.keys():\n",
    "        # Since this data structure is a defaultdict, this will only iterate over the defined (i.e. seen)\n",
    "        # nucleotide indices (integers in the range [0, 3]).\n",
    "        for nt in pos2nt2freq[pos].keys():\n",
    "            # Set the \"freq\" attribute of this allele node to the number of times this nucleotide was seen\n",
    "            # at this position in the reads. This corresponds to Reads(i, N) for position i and nt N.\n",
    "            g.add_node((pos, nt), freq=pos2nt2freq[pos][nt])\n",
    "    \n",
    "    # Next step: add edges to the graph based on co-occurrence information\n",
    "    with open(f\"phasing-data/{seq}_pospair2ntpair2freq.pickle\", \"rb\") as loadster:\n",
    "        pospair2ntpair2freq = pickle.load(loadster)\n",
    "    \n",
    "    for pospair in pospair2ntpair2freq:\n",
    "        i = pospair[0]\n",
    "        j = pospair[1]\n",
    "        \n",
    "        # NOTE: possible to speed this up by bundling this computation into the for loop below, maybe\n",
    "        # also note that \"num spanning reads\" only includes reads that meet criteria about not having\n",
    "        # skips/indels at either position, etc.\n",
    "        num_spanning_reads = sum(pospair2ntpair2freq[pospair].values())\n",
    "        \n",
    "        if num_spanning_reads > MINSPAN:\n",
    "            for ntpair in pospair2ntpair2freq[pospair]:\n",
    "                # these are still ints in the range [0, 3]\n",
    "                i_nt = ntpair[0]\n",
    "                j_nt = ntpair[1]\n",
    "                link = pospair2ntpair2freq[pospair][ntpair] / max(pos2nt2freq[i][i_nt], pos2nt2freq[j][j_nt])\n",
    "                if link > MINLINK_EXCLUSIVE:\n",
    "                    # Yay, add an edge between these alleles!\n",
    "                    g.add_edge((i, i_nt), (j, j_nt), link=link)\n",
    "                    \n",
    "    with open(f\"phasing-data/{seq}_linkgraph.pickle\", \"wb\") as dumpster:\n",
    "        dumpster.write(pickle.dumps(g))\n",
    "        \n",
    "print(f\"Time taken: {time.time() - t1:,} sec.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
