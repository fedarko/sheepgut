{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alike-occurrence",
   "metadata": {},
   "source": [
    "# Generate misc. text files that can be loaded directly into LaTeX\n",
    "\n",
    "The objective of this is to reduce the amount of stuff I have to keep updating in the report manually -- this should both reduce errors and save time when re-running things.\n",
    "\n",
    "This file does not necessarily generate all of the stuff in `misc-text/` -- I will probably split this up if it gets unwieldy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-color",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T00:31:33.086516Z",
     "iopub.status.busy": "2021-06-13T00:31:33.085597Z",
     "iopub.status.idle": "2021-06-13T00:31:51.390603Z",
     "shell.execute_reply": "2021-06-13T00:31:51.389643Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"Header.ipynb\"\n",
    "%run \"GeneUtils.ipynb\"\n",
    "import pileup\n",
    "seq2pos2pileup = pileup.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-surgeon",
   "metadata": {},
   "source": [
    "## Describe the number of mutated positions with \"ties\" in the most-common mutation\n",
    "\n",
    "As might be expected, there are not a lot of these positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "piano-reservation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T00:31:51.465587Z",
     "iopub.status.busy": "2021-06-13T00:31:51.429409Z",
     "iopub.status.idle": "2021-06-13T00:31:58.955458Z",
     "shell.execute_reply": "2021-06-13T00:31:58.954724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-freq-alt-nt tie at seq edge_1671, pos 1,381,119, pileup [[38, 38, 0, 1414], 3, 0].\n",
      "Max-freq-alt-nt tie at seq edge_2358, pos 47,221, pileup [[14, 2637, 6, 14], 1, 4].\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "\n",
    "numties = 0\n",
    "for seq in SEQS:\n",
    "    for pos in range(1, seq2len[seq] + 1):\n",
    "        if pileup.naively_call_mutation(seq2pos2pileup[seq][pos], p):\n",
    "            alts = pileup.get_mismatch_cts(seq2pos2pileup[seq][pos])\n",
    "            if alts.count(max(alts)) > 1:\n",
    "                numties += 1\n",
    "                # Printing this is just for my own sanity\n",
    "                # ALSO: If you're wondering why we only got one warning in the highly mutated gene tables\n",
    "                # ntbk about this (as of writing), it's because just one of these two positions is in\n",
    "                # a gene (in edge 1671); the other of these two positions is in an intergenic region in edge 2358\n",
    "                print(f\"Max-freq-alt-nt tie at seq {seq}, pos {pos:,}, pileup {seq2pos2pileup[seq][pos]}.\")\n",
    "\n",
    "with open(\"misc-text/num-alt-nt-ties.tex\", \"w\") as of:\n",
    "    # see https://tex.stackexchange.com/a/18018\n",
    "    of.write(\"{}\\endinput\".format(numties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-mortgage",
   "metadata": {},
   "source": [
    "## Count the number of reads with supplementary alignments, and with _overlapping_ supplementary alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ancient-duplicate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T00:31:58.964157Z",
     "iopub.status.busy": "2021-06-13T00:31:58.963307Z",
     "iopub.status.idle": "2021-06-13T00:32:51.045107Z",
     "shell.execute_reply": "2021-06-13T00:32:51.045816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On seq CAMP.\n",
      "Average number of alignments of reads with supp alignments: 2.07484\n",
      "Unique reads in unfiltered aln: 503,385\n",
      "Unique reads in filtered aln: 498,584\n",
      "On seq BACT1.\n",
      "Average number of alignments of reads with supp alignments: 2.04318\n",
      "Unique reads in unfiltered aln: 268,075\n",
      "Unique reads in filtered aln: 267,556\n",
      "On seq BACT2.\n",
      "Average number of alignments of reads with supp alignments: 2.04184\n",
      "Unique reads in unfiltered aln: 745,461\n",
      "Unique reads in filtered aln: 744,512\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "bf = pysam.AlignmentFile(\"../main-workflow/output/aln-sorted.bam\", \"rb\")\n",
    "bf2 = pysam.AlignmentFile(\"../main-workflow/output/overlap-supp-aln-filtered-and-sorted-aln.bam\", \"rb\")\n",
    "\n",
    "outputtext = (\n",
    "    \"Before filtering overlapping supplementary alignments and before filtering\\n\"\n",
    "    \"partially-mapped reads, the following supplementary alignment statistics held.\\n\"\n",
    ")\n",
    "\n",
    "for seqi, seq in enumerate(SEQS):\n",
    "    print(f\"On seq {seq2name[seq]}.\")\n",
    "    read2refranges = defaultdict(list)\n",
    "    read2atleast_one_supp_seen = defaultdict(bool)\n",
    "    for ri, read in enumerate(bf.fetch(seq), 1):\n",
    "        rn = read.query_name\n",
    "        rng = range(read.reference_start, read.reference_end)\n",
    "        read2refranges[rn].append(rng)\n",
    "        if read.is_supplementary:\n",
    "            read2atleast_one_supp_seen[rn] = True\n",
    "\n",
    "    reads_with_supp_ct = 0\n",
    "    overlap_lens = []\n",
    "    num_alns_of_reads_with_supp = []\n",
    "    reads_with_overlap_ct = 0\n",
    "    for r in read2refranges:\n",
    "        if len(read2refranges[r]) > 1:\n",
    "            reads_with_supp_ct += 1\n",
    "            num_alns_of_reads_with_supp.append(len(read2refranges[r]))\n",
    "            aln_overlaps = []\n",
    "            for combo in combinations(read2refranges[r], 2):\n",
    "                range_overlap = set(combo[0]) & set(combo[1])\n",
    "                if range_overlap:\n",
    "                    aln_overlaps.append(len(range_overlap))\n",
    "            if len(aln_overlaps) > 0:\n",
    "                reads_with_overlap_ct += 1\n",
    "                overlap_lens += aln_overlaps\n",
    "\n",
    "    numreads = len(read2refranges)\n",
    "    pctreadswithsupp = 100 * (reads_with_supp_ct / numreads)\n",
    "    pctreadswithoverlaps = 100 * (reads_with_overlap_ct / numreads)\n",
    "    avgoverlap = mean(overlap_lens)\n",
    "    avg_num_alignments = mean(num_alns_of_reads_with_supp)\n",
    "    \n",
    "    print(f\"Average number of alignments of reads with supp alignments: {avg_num_alignments:,.5f}\")\n",
    "    \n",
    "    print(f\"Unique reads in unfiltered aln: {numreads:,}\")\n",
    "    \n",
    "    # This small block of code verifies that the OSA-filtered alignment doesn't actually remove any UNIQUE\n",
    "    # reads. Eventually this code should be removed from here and stored in a dedicated test module.\n",
    "    unique_reads_in_filtered_aln = set()\n",
    "    for ri2, read2 in enumerate(bf2.fetch(seq), 1):\n",
    "        rn2 = read2.query_name\n",
    "        unique_reads_in_filtered_aln.add(rn2)\n",
    "    numreads2 = len(unique_reads_in_filtered_aln)\n",
    "    print(f\"Unique reads in filtered aln: {numreads2:,}\")\n",
    "    \n",
    "    # Add extra line break btwn. adjacent sentences\n",
    "    outputtext += \"\\n\"\n",
    "        \n",
    "    outputtext += (\n",
    "        f\"In the {seq2name[seq]} genome, {reads_with_supp_ct:,} / {numreads:,}\"\n",
    "        f\" ({pctreadswithsupp:.2f}\\\\%) unique reads aligned to within the genome had supplementary alignments\"\n",
    "        f\" within {seq2name[seq]}.\\nOn average, these {reads_with_supp_ct:,} reads had {avg_num_alignments:.2f}\"\n",
    "        f\" alignments within {seq2name[seq]}.\\n\"\n",
    "        f\"Furthermore, {reads_with_overlap_ct:,} / {numreads:,} ({pctreadswithoverlaps:.2f}\\\\%)\"\n",
    "        f\" unique reads aligned to within {seq2name[seq]} had supplementary alignments within {seq2name[seq]}\"\n",
    "        \" \\emph{and} had reference overlap between at least one pair of their alignments within\"\n",
    "        f\" {seq2name[seq]}.\\nThe\"\n",
    "        f\" average length of these overlaps (considering all pairs of overlapping alignments\"\n",
    "        f\" within {seq2name[seq]} from the same read) was {avgoverlap:,.2f} bp.\\n\"\n",
    "    )\n",
    "    \n",
    "    # Also really quick, validate that none of the reads with multiple alignments lack supp alignments.\n",
    "    # This could happen if we forgot to filter secondary reads or something.\n",
    "    for r in read2refranges:\n",
    "        if len(read2refranges[r]) > 1:\n",
    "            if not read2atleast_one_supp_seen[r]:\n",
    "                print(f\"Read {r} had no supplementary alignments but still has multiple alignments???\")\n",
    "                \n",
    "with open(\"misc-text/overlapping-supp-aln-stats.tex\", \"w\") as of:\n",
    "    of.write(\"{}\\endinput\".format(outputtext))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14290e",
   "metadata": {},
   "source": [
    "## Count the codon positions of the $p = 0.5\\%$ mutations in the highest-mutation-rate gene in CAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec8bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_sco\n",
    "camp_genes = parse_sco.parse_sco(\"../seqs/genes/edge_6104.sco\")\n",
    "\n",
    "# Check that this gene exists -- imaybe its coordinates might slightly shift or something if we change some\n",
    "# prodigal parameters, but in that case I'll need to change the number I'm using here\n",
    "g = camp_genes.loc[1217]\n",
    "assert g.LeftEnd == 1208927 and g.RightEnd == 1210075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "762096ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CP 3 mutation at position 1,209,001. Pileup: [[3757, 1, 709, 3], 0, 0]\n",
      "Found CP 3 mutation at position 1,209,010. Pileup: [[3744, 703, 0, 0], 0, 26]\n",
      "Found CP 3 mutation at position 1,209,022. Pileup: [[3758, 0, 711, 1], 0, 0]\n",
      "Found CP 3 mutation at position 1,209,058. Pileup: [[0, 3773, 0, 718], 1, 0]\n",
      "Found CP 1 mutation at position 1,209,104. Pileup: [[1, 3777, 0, 713], 1, 4]\n",
      "Found CP 3 mutation at position 1,209,115. Pileup: [[706, 3773, 0, 1], 1, 10]\n",
      "Found CP 3 mutation at position 1,209,121. Pileup: [[713, 1, 3778, 0], 2, 2]\n",
      "Found CP 2 mutation at position 1,209,126. Pileup: [[3777, 1, 712, 1], 0, 3]\n",
      "Found CP 3 mutation at position 1,209,133. Pileup: [[710, 0, 3775, 2], 2, 6]\n",
      "Found CP 3 mutation at position 1,209,136. Pileup: [[1, 717, 1, 3772], 3, 1]\n",
      "Found CP 3 mutation at position 1,209,142. Pileup: [[717, 0, 3777, 0], 2, 0]\n",
      "Found CP 3 mutation at position 1,209,145. Pileup: [[1, 3776, 0, 715], 1, 1]\n",
      "Found CP 3 mutation at position 1,209,148. Pileup: [[3778, 0, 0, 714], 0, 4]\n",
      "Found CP 3 mutation at position 1,209,154. Pileup: [[714, 1, 1, 3778], 3, 3]\n",
      "Found CP 3 mutation at position 1,209,205. Pileup: [[717, 0, 3779, 0], 2, 13]\n",
      "Found CP 3 mutation at position 1,209,241. Pileup: [[725, 0, 3789, 1], 2, 8]\n",
      "Found CP 3 mutation at position 1,209,265. Pileup: [[1, 720, 3, 3791], 3, 2]\n",
      "Found CP 1 mutation at position 1,209,266. Pileup: [[0, 3796, 719, 2], 1, 0]\n",
      "Found CP 2 mutation at position 1,209,297. Pileup: [[1, 723, 0, 3790], 3, 3]\n",
      "Found CP 3 mutation at position 1,209,322. Pileup: [[2, 3784, 0, 726], 1, 0]\n",
      "Found CP 3 mutation at position 1,209,325. Pileup: [[1, 3780, 1, 725], 1, 2]\n",
      "Found CP 3 mutation at position 1,209,337. Pileup: [[0, 725, 0, 3784], 3, 1]\n",
      "Found CP 3 mutation at position 1,209,400. Pileup: [[2, 722, 1, 3783], 3, 1]\n",
      "Found CP 3 mutation at position 1,209,403. Pileup: [[3783, 0, 719, 2], 0, 3]\n",
      "Found CP 3 mutation at position 1,209,418. Pileup: [[3787, 0, 719, 0], 0, 1]\n",
      "Found CP 3 mutation at position 1,209,421. Pileup: [[1, 3784, 3, 716], 1, 3]\n",
      "Found CP 3 mutation at position 1,209,424. Pileup: [[0, 722, 1, 3788], 3, 0]\n",
      "Found CP 3 mutation at position 1,209,523. Pileup: [[3795, 0, 727, 0], 0, 0]\n",
      "Found CP 3 mutation at position 1,209,577. Pileup: [[3799, 0, 729, 0], 0, 7]\n",
      "Found CP 3 mutation at position 1,209,610. Pileup: [[2, 3801, 6, 728], 1, 2]\n",
      "Found CP 3 mutation at position 1,209,697. Pileup: [[735, 0, 0, 3812], 3, 0]\n",
      "Found CP 3 mutation at position 1,209,700. Pileup: [[0, 735, 0, 3811], 3, 1]\n",
      "Found CP 3 mutation at position 1,209,757. Pileup: [[3820, 0, 723, 0], 0, 3]\n",
      "Found CP 3 mutation at position 1,209,796. Pileup: [[3819, 0, 730, 0], 0, 0]\n",
      "-------------------------------------------------------------------------------\n",
      "34 positions (2 in CP1, 2 in CP2, and 30 in CP3) have mutation frequencies close to 16\\%, while all remaining positions in this gene have mutation rates of at most 0.38\\%.\n"
     ]
    }
   ],
   "source": [
    "pCeil = 20\n",
    "pHi = 15\n",
    "pLo = 0.5\n",
    "\n",
    "max_non_mutated_alt_pct = float(\"-inf\")\n",
    "\n",
    "mutation_count = 0\n",
    "# Records number of mutations at CP 1, 2, 3 within this gene\n",
    "mutated_cp_count = [0, 0, 0]\n",
    "cp = 1\n",
    "for pos in range(g.LeftEnd, g.RightEnd + 1):\n",
    "    pospileup = seq2pos2pileup[\"edge_6104\"][pos]\n",
    "    if pileup.naively_call_mutation(pospileup, pLo):\n",
    "        mutated_cp_count[cp - 1] += 1\n",
    "        mutation_count += 1\n",
    "        print(f\"Found CP {cp} mutation at position {pos:,}. Pileup: {pospileup}\")\n",
    "        \n",
    "        # ensure that all p = 0.5% mutations are also the close-to-p=16% mutations. Not a big deal if not,\n",
    "        # but the text does describe this so we should make sure we're correct.\n",
    "        assert pileup.naively_call_mutation(seq2pos2pileup[\"edge_6104\"][pos], pHi)\n",
    "        assert not pileup.naively_call_mutation(seq2pos2pileup[\"edge_6104\"][pos], pCeil)\n",
    "    else:\n",
    "        max_non_mutated_alt_pct = max(max_non_mutated_alt_pct, pileup.get_alt_nt_pct(pospileup))\n",
    "        \n",
    "    cp += 1\n",
    "    \n",
    "    # yes i'm aware we could just use modulos, but i'm tired\n",
    "    if cp == 4:\n",
    "        cp = 1\n",
    "    elif cp > 4:\n",
    "        raise ValueError(\n",
    "            \"marcus can't do basic math, if you get this error message send him an email laughing at him\"\n",
    "        )\n",
    "\n",
    "# If this isn't true, something went very wrong!\n",
    "assert mutation_count == sum(mutated_cp_count)\n",
    "\n",
    "cp1, cp2, cp3 = mutated_cp_count\n",
    "text = (\n",
    "    f\"{mutation_count:,} positions ({cp1:,} in CP1, {cp2:,} in CP2, and {cp3:,} in CP3) have mutation \"\n",
    "    f\"frequencies close to 16\\%, while all remaining positions in this gene have mutation rates of at \"\n",
    "    f\"most {max_non_mutated_alt_pct * 100:.2f}\\%.\"\n",
    ")\n",
    "print(\"-\" * 79)\n",
    "print(text)\n",
    "\n",
    "with open(\"misc-text/camp-g1217-cpstats.tex\", \"w\") as of:\n",
    "    of.write(\"{}\\endinput\".format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f584b8",
   "metadata": {},
   "source": [
    "## How many $p = 1\\%$ mutations across each of the three MAGs have at least one deletion aligned?\n",
    "\n",
    "This is likely a reason why the BACT1 smooth phasing graph looks so simple, in comparison -- a lot of stuff has been filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c607157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMP:\n",
      "  57 / 83 (68.67%) p = 1% muts have ≥ 1 deletion in the pileup.\n",
      "  23 / 83 (27.71%) p = 1% muts have ≥ 5 deletions in the pileup.\n",
      "  12 / 83 (14.46%) p = 1% muts have ≥ 15 deletions in the pileup.\n",
      "BACT1:\n",
      "  8,269 / 22,415 (36.89%) p = 1% muts have ≥ 1 deletion in the pileup.\n",
      "  2,159 / 22,415 (9.63%) p = 1% muts have ≥ 5 deletions in the pileup.\n",
      "  872 / 22,415 (3.89%) p = 1% muts have ≥ 15 deletions in the pileup.\n",
      "BACT2:\n",
      "  274 / 380 (72.11%) p = 1% muts have ≥ 1 deletion in the pileup.\n",
      "  189 / 380 (49.74%) p = 1% muts have ≥ 5 deletions in the pileup.\n",
      "  151 / 380 (39.74%) p = 1% muts have ≥ 15 deletions in the pileup.\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "\n",
    "num_muts_total = defaultdict(int)\n",
    "num_muts_with_at_least_1_deletion = defaultdict(int)\n",
    "num_muts_with_at_least_5_deletions = defaultdict(int)\n",
    "num_muts_with_at_least_15_deletions = defaultdict(int)\n",
    "\n",
    "for seq in SEQS:\n",
    "    for pos in range(1, seq2len[seq] + 1):\n",
    "        if pileup.naively_call_mutation(seq2pos2pileup[seq][pos], p):\n",
    "            num_muts_total[seq] += 1\n",
    "            num_del = pileup.get_deletions(seq2pos2pileup[seq][pos])\n",
    "            if num_del >= 1:\n",
    "                num_muts_with_at_least_1_deletion[seq] += 1\n",
    "                # print(f\"Seq {seq} has {num_del:,} deletions at pos {pos:,}\")\n",
    "                if num_del >= 5:\n",
    "                    num_muts_with_at_least_5_deletions[seq] += 1\n",
    "                    if num_del >= 15:\n",
    "                        num_muts_with_at_least_15_deletions[seq] += 1\n",
    "\n",
    "                    \n",
    "    print(\n",
    "        f\"{seq2name[seq]}:\\n  {num_muts_with_at_least_1_deletion[seq]:,} / {num_muts_total[seq]:,} \"\n",
    "        f\"({(num_muts_with_at_least_1_deletion[seq] / num_muts_total[seq]) * 100:.2f}%) \"\n",
    "        f\"p = 1% muts have ≥ 1 deletion in the pileup.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  {num_muts_with_at_least_5_deletions[seq]:,} / {num_muts_total[seq]:,} \"\n",
    "        f\"({(num_muts_with_at_least_5_deletions[seq] / num_muts_total[seq]) * 100:.2f}%) \"\n",
    "        f\"p = 1% muts have ≥ 5 deletions in the pileup.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  {num_muts_with_at_least_15_deletions[seq]:,} / {num_muts_total[seq]:,} \"\n",
    "        f\"({(num_muts_with_at_least_15_deletions[seq] / num_muts_total[seq]) * 100:.2f}%) \"\n",
    "        f\"p = 1% muts have ≥ 15 deletions in the pileup.\"\n",
    "    )\n",
    "                    \n",
    "# with open(\"misc-text/num-alt-nt-ties.tex\", \"w\") as of:\n",
    "#     # see https://tex.stackexchange.com/a/18018\n",
    "#     of.write(\"{}\\endinput\".format(numties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ad1bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'edge_6104': 57, 'edge_1671': 8269, 'edge_2358': 274})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_muts_with_at_least_1_deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbd2acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'edge_6104': 23, 'edge_1671': 2159, 'edge_2358': 189})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_muts_with_at_least_5_deletions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
